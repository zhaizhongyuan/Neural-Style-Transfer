{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgBJi5f5G1Zk",
        "outputId": "612b25bc-c3e1-4bd4-f7c0-7fc069ca882a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXdlA6nHIJVO",
        "outputId": "9519013b-2cde-4592-e8e8-7b1c972dc0fa"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "image_dir = os.getcwd() + '/Images/'\n",
        "model_dir = os.getcwd() + '/Models/'\n",
        "output_dir = os.getcwd() + '/Output/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z-P_kQM_EJ0S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "print(device)\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "content_images = [\"Content/04.png\", \"Content/01.png\", \"Content/05.png\", \"Content/10.png\", \"Content/12.png\", \"Content/19.png\"]\n",
        "style_images = [\"Style/01.png\", \"Style/02.png\", \"Style/03.png\", \"Style/10.png\", \"Style/04.png\", \"Style/09.png\"]\n",
        "n_iterations = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "Ut1iHi6kEJ0U"
      },
      "outputs": [],
      "source": [
        "#vgg definition that conveniently let's you grab the outputs from any layer\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, pool='max'):\n",
        "        super(VGG, self).__init__()\n",
        "        #vgg modules\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        if pool == 'max':\n",
        "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif pool == 'avg':\n",
        "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            \n",
        "    def forward(self, x, out_keys):\n",
        "        out = {}\n",
        "        out['r11'] = F.relu(self.conv1_1(x))\n",
        "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
        "        out['p1'] = self.pool1(out['r12'])\n",
        "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
        "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
        "        out['p2'] = self.pool2(out['r22'])\n",
        "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
        "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
        "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
        "        out['r34'] = F.relu(self.conv3_4(out['r33']))\n",
        "        out['p3'] = self.pool3(out['r34'])\n",
        "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
        "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
        "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
        "        out['r44'] = F.relu(self.conv4_4(out['r43']))\n",
        "        out['p4'] = self.pool4(out['r44'])\n",
        "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
        "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
        "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
        "        out['r54'] = F.relu(self.conv5_4(out['r53']))\n",
        "        out['p5'] = self.pool5(out['r54'])\n",
        "        return [out[key] for key in out_keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "brzisSSLEJ0V"
      },
      "outputs": [],
      "source": [
        "# gram matrix and loss\n",
        "class GramMatrix(nn.Module):\n",
        "    def forward(self, input):\n",
        "        b,c,h,w = input.size()\n",
        "        F = input.view(b, c, h*w)\n",
        "        G = torch.bmm(F, F.transpose(1,2)) \n",
        "        G.div_(h*w)\n",
        "        return G\n",
        "\n",
        "class GramMSELoss(nn.Module):\n",
        "    def forward(self, input, target):\n",
        "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
        "        return(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R1THuFExEJ0V"
      },
      "outputs": [],
      "source": [
        "# pre and post processing for images\n",
        "img_size = 512 \n",
        "prep = transforms.Compose([transforms.Resize(img_size),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR\n",
        "                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean\n",
        "                                                std=[1,1,1]),\n",
        "                           transforms.Lambda(lambda x: x.mul_(255)),\n",
        "                          ])\n",
        "postpa = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n",
        "                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], #add imagenet mean\n",
        "                                                std=[1,1,1]),\n",
        "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB\n",
        "                           ])\n",
        "postpb = transforms.Compose([transforms.ToPILImage()])\n",
        "def postp(tensor): # to clip results in the range [0,1]\n",
        "    t = postpa(tensor)\n",
        "    t[t>1] = 1    \n",
        "    t[t<0] = 0\n",
        "    img = postpb(t)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IPymFEN7EJ0W"
      },
      "outputs": [],
      "source": [
        "#get network\n",
        "vgg = VGG(pool=\"max\")\n",
        "vgg.load_state_dict(torch.load(model_dir + 'vgg_conv.pth'))\n",
        "for param in vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "if torch.cuda.is_available():\n",
        "    vgg.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t5K1UiJLEJ0X"
      },
      "outputs": [],
      "source": [
        "def run_transfer(style_name, content_name, init_method=\"content\", max_iter=500, show_iter=50, output_dir=output_dir):\n",
        "    #load images, ordered as [style_image, content_image]\n",
        "    img_dirs = [image_dir, image_dir]\n",
        "    img_names = [style_name, content_name]\n",
        "    imgs = [Image.open(img_dirs[i] + name) for i,name in enumerate(img_names)]\n",
        "    imgs_torch = [prep(img) for img in imgs]\n",
        "    if torch.cuda.is_available():\n",
        "        imgs_torch = [Variable(img.unsqueeze(0).cuda()) for img in imgs_torch]\n",
        "    else:\n",
        "        imgs_torch = [Variable(img.unsqueeze(0)) for img in imgs_torch]\n",
        "    style_image, content_image = imgs_torch\n",
        "\n",
        "    if init_method == \"random\":\n",
        "        opt_img = Variable(torch.randn(content_image.size()).type_as(content_image.data), requires_grad=True)\n",
        "    elif init_method == \"content\":\n",
        "        opt_img = Variable(content_image.data.clone(), requires_grad=True)\n",
        "    elif init_method == \"style\":\n",
        "        resize_to_content = transforms.Resize((imgs[1].height, imgs[1].width))\n",
        "        style_image_resized = resize_to_content(imgs[0])\n",
        "        if torch.cuda.is_available():\n",
        "            opt_img = Variable(prep(style_image_resized).unsqueeze(0).cuda(), requires_grad=True)\n",
        "        else:\n",
        "            opt_img = Variable(prep(style_image_resized).unsqueeze(0), requires_grad=True)\n",
        "\n",
        "    optimizer = optim.LBFGS([opt_img])\n",
        "    n_iter=[0]\n",
        "\n",
        "    #define layers, loss functions, weights and compute optimization targets\n",
        "    style_layers = ['r11','r21','r31','r41','r51'] \n",
        "    content_layers = ['r42']\n",
        "    loss_layers = style_layers + content_layers\n",
        "    loss_fns = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
        "    if torch.cuda.is_available():\n",
        "        loss_fns = [loss_fn.cuda() for loss_fn in loss_fns]\n",
        "        \n",
        "    #these are good weights settings:\n",
        "    style_weights = [1e3/n**2 for n in [64,128,256,512,512]]\n",
        "    content_weights = [1e0]\n",
        "    weights = style_weights + content_weights\n",
        "\n",
        "    #compute optimization targets\n",
        "    style_targets = [GramMatrix()(A).detach() for A in vgg(style_image, style_layers)]\n",
        "    content_targets = [A.detach() for A in vgg(content_image, content_layers)]\n",
        "    targets = style_targets + content_targets\n",
        "\n",
        "    # set up timer\n",
        "    losses = []\n",
        "\n",
        "    #run style transfer\n",
        "    while n_iter[0] <= max_iter:\n",
        "\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            out = vgg(opt_img, loss_layers)\n",
        "            layer_losses = [weights[a] * loss_fns[a](A, targets[a]) for a,A in enumerate(out)]\n",
        "            loss = torch.stack(layer_losses, dim=0).sum(dim=0)\n",
        "            loss.backward()\n",
        "            n_iter[0]+=1\n",
        "            if n_iter[0]%show_iter == (show_iter-1):\n",
        "                print('Iteration: %d, loss: %f'%(n_iter[0]+1, loss.item()))\n",
        "                losses.append(loss.item())\n",
        "            return loss\n",
        "        \n",
        "        optimizer.step(closure)\n",
        "        \n",
        "    #display result\n",
        "    out_img = postp(opt_img.data[0].cpu().squeeze())\n",
        "    #plt.imshow(out_img)\n",
        "    #plt.gcf().set_size_inches(10,10)\n",
        "    out_img.save(output_dir + \"c\" + content_name[8:10] + \"_s\" + style_name[6:8] + \".png\")\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 5133713.000000\n",
            "Iteration: 50, loss: 2191064.750000\n",
            "Iteration: 75, loss: 1137770.000000\n",
            "Iteration: 100, loss: 786459.187500\n",
            "Iteration: 125, loss: 626609.625000\n",
            "Iteration: 150, loss: 524691.250000\n",
            "Iteration: 175, loss: 458600.062500\n",
            "Iteration: 200, loss: 409446.687500\n",
            "Iteration: 225, loss: 376876.281250\n",
            "Iteration: 250, loss: 351227.781250\n",
            "Iteration: 275, loss: 330924.312500\n",
            "Iteration: 300, loss: 314835.562500\n",
            "Iteration: 325, loss: 302623.312500\n",
            "Iteration: 350, loss: 292596.750000\n",
            "Iteration: 375, loss: 284417.562500\n",
            "Iteration: 400, loss: 278112.718750\n",
            "Iteration: 425, loss: 272721.812500\n",
            "Iteration: 450, loss: 268322.312500\n",
            "Iteration: 475, loss: 264682.656250\n",
            "Iteration: 500, loss: 261158.078125\n",
            "Iteration: 525, loss: 258276.109375\n",
            "Iteration: 550, loss: 255635.906250\n",
            "Iteration: 575, loss: 253309.562500\n",
            "Iteration: 600, loss: 251171.375000\n",
            "Iteration: 625, loss: 249309.484375\n",
            "Iteration: 650, loss: 247690.796875\n",
            "Iteration: 675, loss: 246109.828125\n",
            "Iteration: 700, loss: 244662.078125\n",
            "Iteration: 725, loss: 243361.281250\n",
            "Iteration: 750, loss: 242192.890625\n",
            "Iteration: 775, loss: 241070.625000\n",
            "Iteration: 800, loss: 240070.718750\n",
            "Iteration: 825, loss: 239132.734375\n",
            "Iteration: 850, loss: 238271.000000\n",
            "Iteration: 875, loss: 237485.375000\n",
            "Iteration: 900, loss: 236716.171875\n",
            "Iteration: 925, loss: 236028.187500\n",
            "Iteration: 950, loss: 235404.109375\n",
            "Iteration: 975, loss: 234792.671875\n",
            "Iteration: 1000, loss: 234218.031250\n",
            "Iteration: 1025, loss: 233663.234375\n",
            "Iteration: 1050, loss: 233192.687500\n",
            "Iteration: 1075, loss: 232688.406250\n",
            "Iteration: 1100, loss: 232240.906250\n",
            "Iteration: 1125, loss: 231808.109375\n",
            "Iteration: 1150, loss: 231375.656250\n",
            "Iteration: 1175, loss: 230981.781250\n",
            "Iteration: 1200, loss: 230597.921875\n",
            "Iteration: 1225, loss: 230217.531250\n",
            "Iteration: 1250, loss: 229901.546875\n",
            "Iteration: 1275, loss: 229590.843750\n",
            "Iteration: 1300, loss: 229278.859375\n",
            "Iteration: 1325, loss: 228991.750000\n",
            "Iteration: 1350, loss: 228706.406250\n",
            "Iteration: 1375, loss: 228424.843750\n",
            "Iteration: 1400, loss: 228151.171875\n",
            "Iteration: 1425, loss: 227899.546875\n",
            "Iteration: 1450, loss: 227666.109375\n",
            "Iteration: 1475, loss: 227436.578125\n",
            "Iteration: 1500, loss: 227224.781250\n",
            "Iteration: 1525, loss: 227010.125000\n",
            "Iteration: 1550, loss: 226811.578125\n",
            "Iteration: 1575, loss: 226607.625000\n",
            "Iteration: 1600, loss: 226411.937500\n",
            "Iteration: 1625, loss: 226230.281250\n",
            "Iteration: 1650, loss: 226048.687500\n",
            "Iteration: 1675, loss: 225858.187500\n",
            "Iteration: 1700, loss: 225693.437500\n",
            "Iteration: 1725, loss: 225536.093750\n",
            "Iteration: 1750, loss: 225387.937500\n",
            "Iteration: 1775, loss: 225230.296875\n",
            "Iteration: 1800, loss: 225081.328125\n",
            "Iteration: 1825, loss: 224936.500000\n",
            "Iteration: 1850, loss: 224793.343750\n",
            "Iteration: 1875, loss: 224661.812500\n",
            "Iteration: 1900, loss: 224533.437500\n",
            "Iteration: 1925, loss: 224415.875000\n",
            "Iteration: 1950, loss: 224297.031250\n",
            "Iteration: 1975, loss: 224184.593750\n",
            "Iteration: 2000, loss: 224064.140625\n",
            "Iteration: 25, loss: 5125073.000000\n",
            "Iteration: 50, loss: 2659083.500000\n",
            "Iteration: 75, loss: 1792019.000000\n",
            "Iteration: 100, loss: 1218387.750000\n",
            "Iteration: 125, loss: 850955.812500\n",
            "Iteration: 150, loss: 621159.062500\n",
            "Iteration: 175, loss: 482164.468750\n",
            "Iteration: 200, loss: 389384.187500\n",
            "Iteration: 225, loss: 322106.750000\n",
            "Iteration: 250, loss: 281038.250000\n",
            "Iteration: 275, loss: 249869.312500\n",
            "Iteration: 300, loss: 227981.031250\n",
            "Iteration: 325, loss: 212035.609375\n",
            "Iteration: 350, loss: 199700.015625\n",
            "Iteration: 375, loss: 189878.609375\n",
            "Iteration: 400, loss: 182261.312500\n",
            "Iteration: 425, loss: 176605.718750\n",
            "Iteration: 450, loss: 171633.890625\n",
            "Iteration: 475, loss: 167302.531250\n",
            "Iteration: 500, loss: 163852.953125\n",
            "Iteration: 525, loss: 160769.734375\n",
            "Iteration: 550, loss: 158174.359375\n",
            "Iteration: 575, loss: 155876.421875\n",
            "Iteration: 600, loss: 153976.703125\n",
            "Iteration: 625, loss: 152182.984375\n",
            "Iteration: 650, loss: 150615.781250\n",
            "Iteration: 675, loss: 149107.390625\n",
            "Iteration: 700, loss: 147785.140625\n",
            "Iteration: 725, loss: 146510.125000\n",
            "Iteration: 750, loss: 145430.203125\n",
            "Iteration: 775, loss: 144442.453125\n",
            "Iteration: 800, loss: 143493.953125\n",
            "Iteration: 825, loss: 142602.125000\n",
            "Iteration: 850, loss: 141790.625000\n",
            "Iteration: 875, loss: 141109.015625\n",
            "Iteration: 900, loss: 140433.796875\n",
            "Iteration: 925, loss: 139808.843750\n",
            "Iteration: 950, loss: 139275.281250\n",
            "Iteration: 975, loss: 138743.281250\n",
            "Iteration: 1000, loss: 138241.062500\n",
            "Iteration: 1025, loss: 137723.625000\n",
            "Iteration: 1050, loss: 137315.968750\n",
            "Iteration: 1075, loss: 136886.265625\n",
            "Iteration: 1100, loss: 136525.734375\n",
            "Iteration: 1125, loss: 136161.546875\n",
            "Iteration: 1150, loss: 135789.828125\n",
            "Iteration: 1175, loss: 135472.906250\n",
            "Iteration: 1200, loss: 135167.562500\n",
            "Iteration: 1225, loss: 134902.359375\n",
            "Iteration: 1250, loss: 134622.843750\n",
            "Iteration: 1275, loss: 134365.343750\n",
            "Iteration: 1300, loss: 134124.671875\n",
            "Iteration: 1325, loss: 133906.218750\n",
            "Iteration: 1350, loss: 133669.531250\n",
            "Iteration: 1375, loss: 133465.484375\n",
            "Iteration: 1400, loss: 133264.828125\n",
            "Iteration: 1425, loss: 133087.187500\n",
            "Iteration: 1450, loss: 132909.734375\n",
            "Iteration: 1475, loss: 132732.015625\n",
            "Iteration: 1500, loss: 132565.781250\n",
            "Iteration: 1525, loss: 132404.859375\n",
            "Iteration: 1550, loss: 132261.312500\n",
            "Iteration: 1575, loss: 132114.125000\n",
            "Iteration: 1600, loss: 131960.750000\n",
            "Iteration: 1625, loss: 131833.156250\n",
            "Iteration: 1650, loss: 131700.078125\n",
            "Iteration: 1675, loss: 131576.062500\n",
            "Iteration: 1700, loss: 131454.296875\n",
            "Iteration: 1725, loss: 131337.843750\n",
            "Iteration: 1750, loss: 131220.062500\n",
            "Iteration: 1775, loss: 131105.625000\n",
            "Iteration: 1800, loss: 130997.937500\n",
            "Iteration: 1825, loss: 130893.343750\n",
            "Iteration: 1850, loss: 130788.156250\n",
            "Iteration: 1875, loss: 130691.828125\n",
            "Iteration: 1900, loss: 130598.468750\n",
            "Iteration: 1925, loss: 130506.859375\n",
            "Iteration: 1950, loss: 130413.906250\n",
            "Iteration: 1975, loss: 130322.156250\n",
            "Iteration: 2000, loss: 130232.960938\n",
            "Iteration: 25, loss: 17618392.000000\n",
            "Iteration: 50, loss: 7248038.500000\n",
            "Iteration: 75, loss: 4558175.000000\n",
            "Iteration: 100, loss: 3277812.750000\n",
            "Iteration: 125, loss: 2508961.500000\n",
            "Iteration: 150, loss: 2040754.750000\n",
            "Iteration: 175, loss: 1709137.750000\n",
            "Iteration: 200, loss: 1479792.750000\n",
            "Iteration: 225, loss: 1295253.250000\n",
            "Iteration: 250, loss: 1162409.000000\n",
            "Iteration: 275, loss: 1059231.625000\n",
            "Iteration: 300, loss: 978118.750000\n",
            "Iteration: 325, loss: 915228.250000\n",
            "Iteration: 350, loss: 862276.500000\n",
            "Iteration: 375, loss: 819393.750000\n",
            "Iteration: 400, loss: 782520.312500\n",
            "Iteration: 425, loss: 753650.562500\n",
            "Iteration: 450, loss: 727657.875000\n",
            "Iteration: 475, loss: 706031.937500\n",
            "Iteration: 500, loss: 688052.375000\n",
            "Iteration: 525, loss: 670817.250000\n",
            "Iteration: 550, loss: 656598.187500\n",
            "Iteration: 575, loss: 644263.250000\n",
            "Iteration: 600, loss: 632979.125000\n",
            "Iteration: 625, loss: 623349.875000\n",
            "Iteration: 650, loss: 614551.625000\n",
            "Iteration: 675, loss: 606583.500000\n",
            "Iteration: 700, loss: 599710.625000\n",
            "Iteration: 725, loss: 593051.500000\n",
            "Iteration: 750, loss: 587115.125000\n",
            "Iteration: 775, loss: 581781.875000\n",
            "Iteration: 800, loss: 576906.562500\n",
            "Iteration: 825, loss: 572360.125000\n",
            "Iteration: 850, loss: 568225.125000\n",
            "Iteration: 875, loss: 564543.750000\n",
            "Iteration: 900, loss: 560960.062500\n",
            "Iteration: 925, loss: 557731.687500\n",
            "Iteration: 950, loss: 554900.687500\n",
            "Iteration: 975, loss: 552127.000000\n",
            "Iteration: 1000, loss: 549679.812500\n",
            "Iteration: 1025, loss: 547366.500000\n",
            "Iteration: 1050, loss: 545136.187500\n",
            "Iteration: 1075, loss: 542977.812500\n",
            "Iteration: 1100, loss: 540960.187500\n",
            "Iteration: 1125, loss: 539151.312500\n",
            "Iteration: 1150, loss: 537346.812500\n",
            "Iteration: 1175, loss: 535580.625000\n",
            "Iteration: 1200, loss: 533942.812500\n",
            "Iteration: 1225, loss: 532350.250000\n",
            "Iteration: 1250, loss: 530828.500000\n",
            "Iteration: 1275, loss: 529391.062500\n",
            "Iteration: 1300, loss: 528062.000000\n",
            "Iteration: 1325, loss: 526791.062500\n",
            "Iteration: 1350, loss: 525633.500000\n",
            "Iteration: 1375, loss: 524511.125000\n",
            "Iteration: 1400, loss: 523369.406250\n",
            "Iteration: 1425, loss: 522369.437500\n",
            "Iteration: 1450, loss: 521372.687500\n",
            "Iteration: 1475, loss: 520441.312500\n",
            "Iteration: 1500, loss: 519527.656250\n",
            "Iteration: 1525, loss: 518649.406250\n",
            "Iteration: 1550, loss: 517802.562500\n",
            "Iteration: 1575, loss: 517025.187500\n",
            "Iteration: 1600, loss: 516199.062500\n",
            "Iteration: 1625, loss: 515465.031250\n",
            "Iteration: 1650, loss: 514778.687500\n",
            "Iteration: 1675, loss: 514016.750000\n",
            "Iteration: 1700, loss: 513258.593750\n",
            "Iteration: 1725, loss: 512584.187500\n",
            "Iteration: 1750, loss: 511938.187500\n",
            "Iteration: 1775, loss: 511252.750000\n",
            "Iteration: 1800, loss: 510626.125000\n",
            "Iteration: 1825, loss: 509976.937500\n",
            "Iteration: 1850, loss: 509344.781250\n",
            "Iteration: 1875, loss: 508723.968750\n",
            "Iteration: 1900, loss: 508128.656250\n",
            "Iteration: 1925, loss: 507532.562500\n",
            "Iteration: 1950, loss: 506993.625000\n",
            "Iteration: 1975, loss: 506509.281250\n",
            "Iteration: 2000, loss: 506041.062500\n",
            "Iteration: 25, loss: 10002088.000000\n",
            "Iteration: 50, loss: 4011067.500000\n",
            "Iteration: 75, loss: 2434328.000000\n",
            "Iteration: 100, loss: 1703381.000000\n",
            "Iteration: 125, loss: 1300347.375000\n",
            "Iteration: 150, loss: 1031720.000000\n",
            "Iteration: 175, loss: 856549.937500\n",
            "Iteration: 200, loss: 731719.375000\n",
            "Iteration: 225, loss: 639638.500000\n",
            "Iteration: 250, loss: 576012.687500\n",
            "Iteration: 275, loss: 526465.812500\n",
            "Iteration: 300, loss: 485512.312500\n",
            "Iteration: 325, loss: 454970.937500\n",
            "Iteration: 350, loss: 432221.500000\n",
            "Iteration: 375, loss: 414292.656250\n",
            "Iteration: 400, loss: 399665.687500\n",
            "Iteration: 425, loss: 387505.500000\n",
            "Iteration: 450, loss: 377520.875000\n",
            "Iteration: 475, loss: 368145.531250\n",
            "Iteration: 500, loss: 359938.062500\n",
            "Iteration: 525, loss: 352570.218750\n",
            "Iteration: 550, loss: 346114.562500\n",
            "Iteration: 575, loss: 340116.250000\n",
            "Iteration: 600, loss: 334566.312500\n",
            "Iteration: 625, loss: 329818.875000\n",
            "Iteration: 650, loss: 325375.250000\n",
            "Iteration: 675, loss: 321414.843750\n",
            "Iteration: 700, loss: 317659.500000\n",
            "Iteration: 725, loss: 314136.843750\n",
            "Iteration: 750, loss: 311052.062500\n",
            "Iteration: 775, loss: 308216.593750\n",
            "Iteration: 800, loss: 305521.250000\n",
            "Iteration: 825, loss: 303114.281250\n",
            "Iteration: 850, loss: 300806.687500\n",
            "Iteration: 875, loss: 298744.718750\n",
            "Iteration: 900, loss: 296897.031250\n",
            "Iteration: 925, loss: 295016.187500\n",
            "Iteration: 950, loss: 293285.343750\n",
            "Iteration: 975, loss: 291805.562500\n",
            "Iteration: 1000, loss: 290284.562500\n",
            "Iteration: 1025, loss: 288808.281250\n",
            "Iteration: 1050, loss: 287548.125000\n",
            "Iteration: 1075, loss: 286356.250000\n",
            "Iteration: 1100, loss: 285303.750000\n",
            "Iteration: 1125, loss: 284202.000000\n",
            "Iteration: 1150, loss: 283287.875000\n",
            "Iteration: 1175, loss: 282348.937500\n",
            "Iteration: 1200, loss: 281586.812500\n",
            "Iteration: 1225, loss: 280734.937500\n",
            "Iteration: 1250, loss: 279938.750000\n",
            "Iteration: 1275, loss: 279268.906250\n",
            "Iteration: 1300, loss: 278623.500000\n",
            "Iteration: 1325, loss: 277914.312500\n",
            "Iteration: 1350, loss: 277267.500000\n",
            "Iteration: 1375, loss: 276669.781250\n",
            "Iteration: 1400, loss: 276135.312500\n",
            "Iteration: 1425, loss: 275567.406250\n",
            "Iteration: 1450, loss: 275038.937500\n",
            "Iteration: 1475, loss: 274568.500000\n",
            "Iteration: 1500, loss: 274151.531250\n",
            "Iteration: 1525, loss: 273678.781250\n",
            "Iteration: 1550, loss: 273239.531250\n",
            "Iteration: 1575, loss: 272767.593750\n",
            "Iteration: 1600, loss: 272389.437500\n",
            "Iteration: 1625, loss: 271985.125000\n",
            "Iteration: 1650, loss: 271578.062500\n",
            "Iteration: 1675, loss: 271195.031250\n",
            "Iteration: 1700, loss: 270825.125000\n",
            "Iteration: 1725, loss: 270486.000000\n",
            "Iteration: 1750, loss: 270143.312500\n",
            "Iteration: 1775, loss: 269764.906250\n",
            "Iteration: 1800, loss: 269444.687500\n",
            "Iteration: 1825, loss: 269153.000000\n",
            "Iteration: 1850, loss: 268860.937500\n",
            "Iteration: 1875, loss: 268555.968750\n",
            "Iteration: 1900, loss: 268231.437500\n",
            "Iteration: 1925, loss: 267938.468750\n",
            "Iteration: 1950, loss: 267609.375000\n",
            "Iteration: 1975, loss: 267372.718750\n",
            "Iteration: 2000, loss: 267095.406250\n",
            "Iteration: 25, loss: 3754941.250000\n",
            "Iteration: 50, loss: 1717083.375000\n",
            "Iteration: 75, loss: 1186496.000000\n",
            "Iteration: 100, loss: 936460.000000\n",
            "Iteration: 125, loss: 802701.250000\n",
            "Iteration: 150, loss: 710101.250000\n",
            "Iteration: 175, loss: 643362.750000\n",
            "Iteration: 200, loss: 595434.875000\n",
            "Iteration: 225, loss: 557925.000000\n",
            "Iteration: 250, loss: 530135.437500\n",
            "Iteration: 275, loss: 507834.718750\n",
            "Iteration: 300, loss: 489106.656250\n",
            "Iteration: 325, loss: 474185.968750\n",
            "Iteration: 350, loss: 461575.406250\n",
            "Iteration: 375, loss: 451178.812500\n",
            "Iteration: 400, loss: 442003.250000\n",
            "Iteration: 425, loss: 434026.343750\n",
            "Iteration: 450, loss: 427229.875000\n",
            "Iteration: 475, loss: 421164.968750\n",
            "Iteration: 500, loss: 415722.250000\n",
            "Iteration: 525, loss: 411196.812500\n",
            "Iteration: 550, loss: 407097.437500\n",
            "Iteration: 575, loss: 403187.312500\n",
            "Iteration: 600, loss: 399676.312500\n",
            "Iteration: 625, loss: 396512.156250\n",
            "Iteration: 650, loss: 393363.750000\n",
            "Iteration: 675, loss: 390771.781250\n",
            "Iteration: 700, loss: 388087.062500\n",
            "Iteration: 725, loss: 385623.750000\n",
            "Iteration: 750, loss: 383465.937500\n",
            "Iteration: 775, loss: 381339.687500\n",
            "Iteration: 800, loss: 379219.250000\n",
            "Iteration: 825, loss: 377285.750000\n",
            "Iteration: 850, loss: 375528.625000\n",
            "Iteration: 875, loss: 373862.093750\n",
            "Iteration: 900, loss: 372285.875000\n",
            "Iteration: 925, loss: 370775.000000\n",
            "Iteration: 950, loss: 369457.343750\n",
            "Iteration: 975, loss: 368084.156250\n",
            "Iteration: 1000, loss: 366874.000000\n",
            "Iteration: 1025, loss: 365764.000000\n",
            "Iteration: 1050, loss: 364698.937500\n",
            "Iteration: 1075, loss: 363714.750000\n",
            "Iteration: 1100, loss: 362733.781250\n",
            "Iteration: 1125, loss: 361796.718750\n",
            "Iteration: 1150, loss: 360874.687500\n",
            "Iteration: 1175, loss: 360019.750000\n",
            "Iteration: 1200, loss: 359210.437500\n",
            "Iteration: 1225, loss: 358432.750000\n",
            "Iteration: 1250, loss: 357721.187500\n",
            "Iteration: 1275, loss: 356960.968750\n",
            "Iteration: 1300, loss: 356260.968750\n",
            "Iteration: 1325, loss: 355619.343750\n",
            "Iteration: 1350, loss: 354991.875000\n",
            "Iteration: 1375, loss: 354325.750000\n",
            "Iteration: 1400, loss: 353713.187500\n",
            "Iteration: 1425, loss: 353132.656250\n",
            "Iteration: 1450, loss: 352577.031250\n",
            "Iteration: 1475, loss: 352017.375000\n",
            "Iteration: 1500, loss: 351459.687500\n",
            "Iteration: 1525, loss: 350929.500000\n",
            "Iteration: 1550, loss: 350452.343750\n",
            "Iteration: 1575, loss: 349995.937500\n",
            "Iteration: 1600, loss: 349561.687500\n",
            "Iteration: 1625, loss: 349110.187500\n",
            "Iteration: 1650, loss: 348682.031250\n",
            "Iteration: 1675, loss: 348281.218750\n",
            "Iteration: 1700, loss: 347867.812500\n",
            "Iteration: 1725, loss: 347455.281250\n",
            "Iteration: 1750, loss: 347093.968750\n",
            "Iteration: 1775, loss: 346745.750000\n",
            "Iteration: 1800, loss: 346406.625000\n",
            "Iteration: 1825, loss: 346070.000000\n",
            "Iteration: 1850, loss: 345761.843750\n",
            "Iteration: 1875, loss: 345456.968750\n",
            "Iteration: 1900, loss: 345153.125000\n",
            "Iteration: 1925, loss: 344845.250000\n",
            "Iteration: 1950, loss: 344586.937500\n",
            "Iteration: 1975, loss: 344340.781250\n",
            "Iteration: 2000, loss: 344094.593750\n",
            "Iteration: 25, loss: 20541878.000000\n",
            "Iteration: 50, loss: 7039493.000000\n",
            "Iteration: 75, loss: 3906668.000000\n",
            "Iteration: 100, loss: 2186506.500000\n",
            "Iteration: 125, loss: 1262538.250000\n",
            "Iteration: 150, loss: 831593.625000\n",
            "Iteration: 175, loss: 643848.875000\n",
            "Iteration: 200, loss: 540022.812500\n",
            "Iteration: 225, loss: 477407.937500\n",
            "Iteration: 250, loss: 436166.937500\n",
            "Iteration: 275, loss: 407250.250000\n",
            "Iteration: 300, loss: 385527.375000\n",
            "Iteration: 325, loss: 368171.562500\n",
            "Iteration: 350, loss: 354966.312500\n",
            "Iteration: 375, loss: 344324.000000\n",
            "Iteration: 400, loss: 335609.218750\n",
            "Iteration: 425, loss: 328536.156250\n",
            "Iteration: 450, loss: 322231.031250\n",
            "Iteration: 475, loss: 316935.593750\n",
            "Iteration: 500, loss: 312027.687500\n",
            "Iteration: 525, loss: 307770.843750\n",
            "Iteration: 550, loss: 303989.593750\n",
            "Iteration: 575, loss: 300583.562500\n",
            "Iteration: 600, loss: 297512.875000\n",
            "Iteration: 625, loss: 294764.718750\n",
            "Iteration: 650, loss: 292251.187500\n",
            "Iteration: 675, loss: 289924.500000\n",
            "Iteration: 700, loss: 287976.375000\n",
            "Iteration: 725, loss: 286123.468750\n",
            "Iteration: 750, loss: 284465.781250\n",
            "Iteration: 775, loss: 282849.187500\n",
            "Iteration: 800, loss: 281470.437500\n",
            "Iteration: 825, loss: 280110.000000\n",
            "Iteration: 850, loss: 278753.625000\n",
            "Iteration: 875, loss: 277517.562500\n",
            "Iteration: 900, loss: 276352.093750\n",
            "Iteration: 925, loss: 275272.656250\n",
            "Iteration: 950, loss: 274222.593750\n",
            "Iteration: 975, loss: 273297.187500\n",
            "Iteration: 1000, loss: 272466.031250\n",
            "Iteration: 1025, loss: 271558.343750\n",
            "Iteration: 1050, loss: 270733.781250\n",
            "Iteration: 1075, loss: 269986.500000\n",
            "Iteration: 1100, loss: 269260.406250\n",
            "Iteration: 1125, loss: 268608.625000\n",
            "Iteration: 1150, loss: 267998.375000\n",
            "Iteration: 1175, loss: 267410.062500\n",
            "Iteration: 1200, loss: 266854.562500\n",
            "Iteration: 1225, loss: 266297.781250\n",
            "Iteration: 1250, loss: 265790.312500\n",
            "Iteration: 1275, loss: 265298.562500\n",
            "Iteration: 1300, loss: 264829.687500\n",
            "Iteration: 1325, loss: 264383.781250\n",
            "Iteration: 1350, loss: 263980.968750\n",
            "Iteration: 1375, loss: 263549.968750\n",
            "Iteration: 1400, loss: 263167.281250\n",
            "Iteration: 1425, loss: 262786.093750\n",
            "Iteration: 1450, loss: 262419.093750\n",
            "Iteration: 1475, loss: 262064.640625\n",
            "Iteration: 1500, loss: 261741.718750\n",
            "Iteration: 1525, loss: 261421.125000\n",
            "Iteration: 1550, loss: 261106.281250\n",
            "Iteration: 1575, loss: 260800.109375\n",
            "Iteration: 1600, loss: 260507.140625\n",
            "Iteration: 1625, loss: 260236.562500\n",
            "Iteration: 1650, loss: 259962.187500\n",
            "Iteration: 1675, loss: 259681.718750\n",
            "Iteration: 1700, loss: 259424.531250\n",
            "Iteration: 1725, loss: 259141.312500\n",
            "Iteration: 1750, loss: 258900.031250\n",
            "Iteration: 1775, loss: 258660.921875\n",
            "Iteration: 1800, loss: 258438.796875\n",
            "Iteration: 1825, loss: 258218.718750\n",
            "Iteration: 1850, loss: 258014.281250\n",
            "Iteration: 1875, loss: 257806.750000\n",
            "Iteration: 1900, loss: 257594.250000\n",
            "Iteration: 1925, loss: 257396.781250\n",
            "Iteration: 1950, loss: 257200.734375\n",
            "Iteration: 1975, loss: 257002.468750\n",
            "Iteration: 2000, loss: 256815.703125\n"
          ]
        }
      ],
      "source": [
        "content_losses = []\n",
        "for i in range(len(style_images)):\n",
        "    content_losses.append(run_transfer(style_images[i], content_images[i], \"content\", 2000, 25, output_dir+'content_max_2000/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 10580157.000000\n",
            "Iteration: 50, loss: 3026037.000000\n",
            "Iteration: 75, loss: 1532063.500000\n",
            "Iteration: 100, loss: 1036080.562500\n",
            "Iteration: 125, loss: 801087.250000\n",
            "Iteration: 150, loss: 678320.562500\n",
            "Iteration: 175, loss: 592750.750000\n",
            "Iteration: 200, loss: 537381.687500\n",
            "Iteration: 225, loss: 497968.906250\n",
            "Iteration: 250, loss: 466707.031250\n",
            "Iteration: 275, loss: 441753.125000\n",
            "Iteration: 300, loss: 421256.625000\n",
            "Iteration: 325, loss: 403873.468750\n",
            "Iteration: 350, loss: 389597.125000\n",
            "Iteration: 375, loss: 377012.718750\n",
            "Iteration: 400, loss: 365779.437500\n",
            "Iteration: 425, loss: 355658.843750\n",
            "Iteration: 450, loss: 346564.281250\n",
            "Iteration: 475, loss: 338766.062500\n",
            "Iteration: 500, loss: 331476.500000\n",
            "Iteration: 525, loss: 324934.250000\n",
            "Iteration: 550, loss: 318771.687500\n",
            "Iteration: 575, loss: 313341.187500\n",
            "Iteration: 600, loss: 308272.031250\n",
            "Iteration: 625, loss: 303659.656250\n",
            "Iteration: 650, loss: 299442.937500\n",
            "Iteration: 675, loss: 295699.625000\n",
            "Iteration: 700, loss: 292229.687500\n",
            "Iteration: 725, loss: 288940.843750\n",
            "Iteration: 750, loss: 286039.187500\n",
            "Iteration: 775, loss: 283166.531250\n",
            "Iteration: 800, loss: 280647.156250\n",
            "Iteration: 825, loss: 278268.125000\n",
            "Iteration: 850, loss: 275913.437500\n",
            "Iteration: 875, loss: 273726.250000\n",
            "Iteration: 900, loss: 271889.031250\n",
            "Iteration: 925, loss: 270023.937500\n",
            "Iteration: 950, loss: 268164.187500\n",
            "Iteration: 975, loss: 266525.562500\n",
            "Iteration: 1000, loss: 264975.625000\n",
            "Iteration: 1025, loss: 263502.156250\n",
            "Iteration: 1050, loss: 262116.796875\n",
            "Iteration: 1075, loss: 260797.171875\n",
            "Iteration: 1100, loss: 259543.531250\n",
            "Iteration: 1125, loss: 258318.859375\n",
            "Iteration: 1150, loss: 257133.093750\n",
            "Iteration: 1175, loss: 256071.859375\n",
            "Iteration: 1200, loss: 255080.765625\n",
            "Iteration: 1225, loss: 254123.328125\n",
            "Iteration: 1250, loss: 253174.687500\n",
            "Iteration: 1275, loss: 252228.515625\n",
            "Iteration: 1300, loss: 251385.562500\n",
            "Iteration: 1325, loss: 250578.000000\n",
            "Iteration: 1350, loss: 249778.531250\n",
            "Iteration: 1375, loss: 248998.140625\n",
            "Iteration: 1400, loss: 248299.796875\n",
            "Iteration: 1425, loss: 247611.406250\n",
            "Iteration: 1450, loss: 246919.578125\n",
            "Iteration: 1475, loss: 246298.906250\n",
            "Iteration: 1500, loss: 245663.640625\n",
            "Iteration: 1525, loss: 245080.640625\n",
            "Iteration: 1550, loss: 244505.843750\n",
            "Iteration: 1575, loss: 243970.031250\n",
            "Iteration: 1600, loss: 243402.578125\n",
            "Iteration: 1625, loss: 242833.718750\n",
            "Iteration: 1650, loss: 242308.125000\n",
            "Iteration: 1675, loss: 241827.687500\n",
            "Iteration: 1700, loss: 241368.171875\n",
            "Iteration: 1725, loss: 240883.062500\n",
            "Iteration: 1750, loss: 240443.125000\n",
            "Iteration: 1775, loss: 240057.625000\n",
            "Iteration: 1800, loss: 239700.656250\n",
            "Iteration: 1825, loss: 239303.359375\n",
            "Iteration: 1850, loss: 238923.156250\n",
            "Iteration: 1875, loss: 238561.015625\n",
            "Iteration: 1900, loss: 238244.421875\n",
            "Iteration: 1925, loss: 237896.093750\n",
            "Iteration: 1950, loss: 237536.234375\n",
            "Iteration: 1975, loss: 237192.921875\n",
            "Iteration: 2000, loss: 236907.125000\n",
            "Iteration: 25, loss: 50832932.000000\n",
            "Iteration: 50, loss: 4163374.000000\n",
            "Iteration: 75, loss: 1736822.500000\n",
            "Iteration: 100, loss: 1132557.250000\n",
            "Iteration: 125, loss: 853941.250000\n",
            "Iteration: 150, loss: 685944.875000\n",
            "Iteration: 175, loss: 564348.500000\n",
            "Iteration: 200, loss: 487106.250000\n",
            "Iteration: 225, loss: 421683.312500\n",
            "Iteration: 250, loss: 371603.125000\n",
            "Iteration: 275, loss: 333342.500000\n",
            "Iteration: 300, loss: 303789.093750\n",
            "Iteration: 325, loss: 281704.937500\n",
            "Iteration: 350, loss: 264771.750000\n",
            "Iteration: 375, loss: 250509.687500\n",
            "Iteration: 400, loss: 238922.375000\n",
            "Iteration: 425, loss: 230123.218750\n",
            "Iteration: 450, loss: 222549.062500\n",
            "Iteration: 475, loss: 215930.000000\n",
            "Iteration: 500, loss: 209903.562500\n",
            "Iteration: 525, loss: 204907.312500\n",
            "Iteration: 550, loss: 200274.218750\n",
            "Iteration: 575, loss: 196142.562500\n",
            "Iteration: 600, loss: 192328.031250\n",
            "Iteration: 625, loss: 188952.718750\n",
            "Iteration: 650, loss: 185744.312500\n",
            "Iteration: 675, loss: 182792.437500\n",
            "Iteration: 700, loss: 179968.062500\n",
            "Iteration: 725, loss: 177340.750000\n",
            "Iteration: 750, loss: 175026.093750\n",
            "Iteration: 775, loss: 172792.390625\n",
            "Iteration: 800, loss: 170797.734375\n",
            "Iteration: 825, loss: 168781.218750\n",
            "Iteration: 850, loss: 167081.500000\n",
            "Iteration: 875, loss: 165467.015625\n",
            "Iteration: 900, loss: 163995.078125\n",
            "Iteration: 925, loss: 162614.171875\n",
            "Iteration: 950, loss: 161357.375000\n",
            "Iteration: 975, loss: 160111.156250\n",
            "Iteration: 1000, loss: 158963.250000\n",
            "Iteration: 1025, loss: 157839.765625\n",
            "Iteration: 1050, loss: 156857.921875\n",
            "Iteration: 1075, loss: 155867.953125\n",
            "Iteration: 1100, loss: 154985.359375\n",
            "Iteration: 1125, loss: 154098.828125\n",
            "Iteration: 1150, loss: 153238.953125\n",
            "Iteration: 1175, loss: 152442.453125\n",
            "Iteration: 1200, loss: 151711.656250\n",
            "Iteration: 1225, loss: 151019.281250\n",
            "Iteration: 1250, loss: 150292.390625\n",
            "Iteration: 1275, loss: 149646.421875\n",
            "Iteration: 1300, loss: 149017.468750\n",
            "Iteration: 1325, loss: 148437.156250\n",
            "Iteration: 1350, loss: 147857.968750\n",
            "Iteration: 1375, loss: 147316.265625\n",
            "Iteration: 1400, loss: 146821.390625\n",
            "Iteration: 1425, loss: 146287.656250\n",
            "Iteration: 1450, loss: 145776.453125\n",
            "Iteration: 1475, loss: 145287.203125\n",
            "Iteration: 1500, loss: 144817.984375\n",
            "Iteration: 1525, loss: 144347.281250\n",
            "Iteration: 1550, loss: 143910.859375\n",
            "Iteration: 1575, loss: 143508.500000\n",
            "Iteration: 1600, loss: 143092.312500\n",
            "Iteration: 1625, loss: 142717.828125\n",
            "Iteration: 1650, loss: 142347.750000\n",
            "Iteration: 1675, loss: 141986.000000\n",
            "Iteration: 1700, loss: 141639.734375\n",
            "Iteration: 1725, loss: 141333.671875\n",
            "Iteration: 1750, loss: 141020.187500\n",
            "Iteration: 1775, loss: 140744.203125\n",
            "Iteration: 1800, loss: 140474.812500\n",
            "Iteration: 1825, loss: 140209.843750\n",
            "Iteration: 1850, loss: 139931.187500\n",
            "Iteration: 1875, loss: 139666.296875\n",
            "Iteration: 1900, loss: 139445.609375\n",
            "Iteration: 1925, loss: 139190.687500\n",
            "Iteration: 1950, loss: 138960.015625\n",
            "Iteration: 1975, loss: 138746.031250\n",
            "Iteration: 2000, loss: 138542.375000\n",
            "Iteration: 25, loss: 218119952.000000\n",
            "Iteration: 50, loss: 27486336.000000\n",
            "Iteration: 75, loss: 11477196.000000\n",
            "Iteration: 100, loss: 6907135.500000\n",
            "Iteration: 125, loss: 4932484.000000\n",
            "Iteration: 150, loss: 3826868.750000\n",
            "Iteration: 175, loss: 3146897.000000\n",
            "Iteration: 200, loss: 2701042.500000\n",
            "Iteration: 225, loss: 2366728.000000\n",
            "Iteration: 250, loss: 2108813.500000\n",
            "Iteration: 275, loss: 1896151.625000\n",
            "Iteration: 300, loss: 1732051.500000\n",
            "Iteration: 325, loss: 1593949.875000\n",
            "Iteration: 350, loss: 1479933.625000\n",
            "Iteration: 375, loss: 1381417.500000\n",
            "Iteration: 400, loss: 1301935.875000\n",
            "Iteration: 425, loss: 1234425.750000\n",
            "Iteration: 450, loss: 1177106.250000\n",
            "Iteration: 475, loss: 1127561.625000\n",
            "Iteration: 500, loss: 1083548.000000\n",
            "Iteration: 525, loss: 1044338.187500\n",
            "Iteration: 550, loss: 1011325.250000\n",
            "Iteration: 575, loss: 982775.375000\n",
            "Iteration: 600, loss: 957207.375000\n",
            "Iteration: 625, loss: 933517.125000\n",
            "Iteration: 650, loss: 913033.312500\n",
            "Iteration: 675, loss: 895558.437500\n",
            "Iteration: 700, loss: 877854.062500\n",
            "Iteration: 725, loss: 862244.937500\n",
            "Iteration: 750, loss: 848930.000000\n",
            "Iteration: 775, loss: 836397.500000\n",
            "Iteration: 800, loss: 824988.375000\n",
            "Iteration: 825, loss: 814195.812500\n",
            "Iteration: 850, loss: 804211.875000\n",
            "Iteration: 875, loss: 794866.625000\n",
            "Iteration: 900, loss: 786387.250000\n",
            "Iteration: 925, loss: 778628.312500\n",
            "Iteration: 950, loss: 771425.625000\n",
            "Iteration: 975, loss: 764617.250000\n",
            "Iteration: 1000, loss: 758169.875000\n",
            "Iteration: 1025, loss: 751885.375000\n",
            "Iteration: 1050, loss: 746098.625000\n",
            "Iteration: 1075, loss: 740548.125000\n",
            "Iteration: 1100, loss: 735593.375000\n",
            "Iteration: 1125, loss: 730772.937500\n",
            "Iteration: 1150, loss: 726127.000000\n",
            "Iteration: 1175, loss: 721851.187500\n",
            "Iteration: 1200, loss: 717668.875000\n",
            "Iteration: 1225, loss: 713891.125000\n",
            "Iteration: 1250, loss: 709902.875000\n",
            "Iteration: 1275, loss: 706266.312500\n",
            "Iteration: 1300, loss: 702825.625000\n",
            "Iteration: 1325, loss: 699336.187500\n",
            "Iteration: 1350, loss: 695963.687500\n",
            "Iteration: 1375, loss: 692911.125000\n",
            "Iteration: 1400, loss: 690039.937500\n",
            "Iteration: 1425, loss: 687137.937500\n",
            "Iteration: 1450, loss: 684559.812500\n",
            "Iteration: 1475, loss: 681965.687500\n",
            "Iteration: 1500, loss: 679332.312500\n",
            "Iteration: 1525, loss: 676777.250000\n",
            "Iteration: 1550, loss: 674417.750000\n",
            "Iteration: 1575, loss: 672080.500000\n",
            "Iteration: 1600, loss: 669685.750000\n",
            "Iteration: 1625, loss: 667371.500000\n",
            "Iteration: 1650, loss: 664992.375000\n",
            "Iteration: 1675, loss: 662882.000000\n",
            "Iteration: 1700, loss: 660750.062500\n",
            "Iteration: 1725, loss: 658675.687500\n",
            "Iteration: 1750, loss: 656450.000000\n",
            "Iteration: 1775, loss: 654413.875000\n",
            "Iteration: 1800, loss: 652484.437500\n",
            "Iteration: 1825, loss: 650474.187500\n",
            "Iteration: 1850, loss: 648679.375000\n",
            "Iteration: 1875, loss: 646846.125000\n",
            "Iteration: 1900, loss: 645116.500000\n",
            "Iteration: 1925, loss: 643430.687500\n",
            "Iteration: 1950, loss: 641797.750000\n",
            "Iteration: 1975, loss: 640200.812500\n",
            "Iteration: 2000, loss: 638506.250000\n",
            "Iteration: 25, loss: 198166256.000000\n",
            "Iteration: 50, loss: 23254758.000000\n",
            "Iteration: 75, loss: 9149118.000000\n",
            "Iteration: 100, loss: 5792070.500000\n",
            "Iteration: 125, loss: 4279612.500000\n",
            "Iteration: 150, loss: 3417475.500000\n",
            "Iteration: 175, loss: 2846431.000000\n",
            "Iteration: 200, loss: 2424474.500000\n",
            "Iteration: 225, loss: 2054317.750000\n",
            "Iteration: 250, loss: 1790280.250000\n",
            "Iteration: 275, loss: 1562211.125000\n",
            "Iteration: 300, loss: 1382551.625000\n",
            "Iteration: 325, loss: 1234536.000000\n",
            "Iteration: 350, loss: 1109965.000000\n",
            "Iteration: 375, loss: 1010257.125000\n",
            "Iteration: 400, loss: 926955.125000\n",
            "Iteration: 425, loss: 857984.125000\n",
            "Iteration: 450, loss: 805124.062500\n",
            "Iteration: 475, loss: 757023.000000\n",
            "Iteration: 500, loss: 718394.562500\n",
            "Iteration: 525, loss: 684557.500000\n",
            "Iteration: 550, loss: 655798.562500\n",
            "Iteration: 575, loss: 631863.375000\n",
            "Iteration: 600, loss: 610543.375000\n",
            "Iteration: 625, loss: 592684.000000\n",
            "Iteration: 650, loss: 575735.875000\n",
            "Iteration: 675, loss: 561655.937500\n",
            "Iteration: 700, loss: 549073.437500\n",
            "Iteration: 725, loss: 536699.937500\n",
            "Iteration: 750, loss: 525870.000000\n",
            "Iteration: 775, loss: 515984.281250\n",
            "Iteration: 800, loss: 507059.781250\n",
            "Iteration: 825, loss: 498451.062500\n",
            "Iteration: 850, loss: 490390.281250\n",
            "Iteration: 875, loss: 481924.687500\n",
            "Iteration: 900, loss: 474534.656250\n",
            "Iteration: 925, loss: 467017.062500\n",
            "Iteration: 950, loss: 459859.437500\n",
            "Iteration: 975, loss: 452979.750000\n",
            "Iteration: 1000, loss: 446199.375000\n",
            "Iteration: 1025, loss: 439877.312500\n",
            "Iteration: 1050, loss: 434041.718750\n",
            "Iteration: 1075, loss: 428353.562500\n",
            "Iteration: 1100, loss: 422762.500000\n",
            "Iteration: 1125, loss: 417557.031250\n",
            "Iteration: 1150, loss: 412661.937500\n",
            "Iteration: 1175, loss: 408015.375000\n",
            "Iteration: 1200, loss: 403685.937500\n",
            "Iteration: 1225, loss: 399326.187500\n",
            "Iteration: 1250, loss: 395392.781250\n",
            "Iteration: 1275, loss: 391655.687500\n",
            "Iteration: 1300, loss: 388231.187500\n",
            "Iteration: 1325, loss: 384859.000000\n",
            "Iteration: 1350, loss: 381862.312500\n",
            "Iteration: 1375, loss: 378989.156250\n",
            "Iteration: 1400, loss: 376436.062500\n",
            "Iteration: 1425, loss: 373894.812500\n",
            "Iteration: 1450, loss: 371429.281250\n",
            "Iteration: 1475, loss: 368992.718750\n",
            "Iteration: 1500, loss: 366831.437500\n",
            "Iteration: 1525, loss: 364655.750000\n",
            "Iteration: 1550, loss: 362591.656250\n",
            "Iteration: 1575, loss: 360589.687500\n",
            "Iteration: 1600, loss: 358624.875000\n",
            "Iteration: 1625, loss: 356901.687500\n",
            "Iteration: 1650, loss: 355205.750000\n",
            "Iteration: 1675, loss: 353484.187500\n",
            "Iteration: 1700, loss: 351869.250000\n",
            "Iteration: 1725, loss: 350279.562500\n",
            "Iteration: 1750, loss: 348729.843750\n",
            "Iteration: 1775, loss: 347050.000000\n",
            "Iteration: 1800, loss: 345356.718750\n",
            "Iteration: 1825, loss: 343809.281250\n",
            "Iteration: 1850, loss: 342367.031250\n",
            "Iteration: 1875, loss: 340895.187500\n",
            "Iteration: 1900, loss: 339538.250000\n",
            "Iteration: 1925, loss: 338294.843750\n",
            "Iteration: 1950, loss: 337081.156250\n",
            "Iteration: 1975, loss: 335879.781250\n",
            "Iteration: 2000, loss: 334787.250000\n",
            "Iteration: 25, loss: 32302448.000000\n",
            "Iteration: 50, loss: 8453264.000000\n",
            "Iteration: 75, loss: 4584437.000000\n",
            "Iteration: 100, loss: 3112174.250000\n",
            "Iteration: 125, loss: 2390602.000000\n",
            "Iteration: 150, loss: 1964862.500000\n",
            "Iteration: 175, loss: 1669305.000000\n",
            "Iteration: 200, loss: 1461213.500000\n",
            "Iteration: 225, loss: 1298349.500000\n",
            "Iteration: 250, loss: 1167455.625000\n",
            "Iteration: 275, loss: 1058590.000000\n",
            "Iteration: 300, loss: 970898.250000\n",
            "Iteration: 325, loss: 898953.875000\n",
            "Iteration: 350, loss: 838212.875000\n",
            "Iteration: 375, loss: 789573.375000\n",
            "Iteration: 400, loss: 748894.125000\n",
            "Iteration: 425, loss: 715269.312500\n",
            "Iteration: 450, loss: 687496.875000\n",
            "Iteration: 475, loss: 664602.375000\n",
            "Iteration: 500, loss: 644791.437500\n",
            "Iteration: 525, loss: 627122.062500\n",
            "Iteration: 550, loss: 611802.750000\n",
            "Iteration: 575, loss: 598925.000000\n",
            "Iteration: 600, loss: 586493.250000\n",
            "Iteration: 625, loss: 575827.125000\n",
            "Iteration: 650, loss: 565983.437500\n",
            "Iteration: 675, loss: 556932.437500\n",
            "Iteration: 700, loss: 548765.437500\n",
            "Iteration: 725, loss: 541450.750000\n",
            "Iteration: 750, loss: 534330.875000\n",
            "Iteration: 775, loss: 528008.062500\n",
            "Iteration: 800, loss: 521898.062500\n",
            "Iteration: 825, loss: 516468.781250\n",
            "Iteration: 850, loss: 511389.312500\n",
            "Iteration: 875, loss: 506566.468750\n",
            "Iteration: 900, loss: 502026.406250\n",
            "Iteration: 925, loss: 497724.843750\n",
            "Iteration: 950, loss: 493581.656250\n",
            "Iteration: 975, loss: 489864.250000\n",
            "Iteration: 1000, loss: 486095.218750\n",
            "Iteration: 1025, loss: 482574.375000\n",
            "Iteration: 1050, loss: 479181.468750\n",
            "Iteration: 1075, loss: 475967.625000\n",
            "Iteration: 1100, loss: 472960.375000\n",
            "Iteration: 1125, loss: 469997.593750\n",
            "Iteration: 1150, loss: 467310.812500\n",
            "Iteration: 1175, loss: 464708.187500\n",
            "Iteration: 1200, loss: 462017.781250\n",
            "Iteration: 1225, loss: 459571.062500\n",
            "Iteration: 1250, loss: 457253.718750\n",
            "Iteration: 1275, loss: 454980.281250\n",
            "Iteration: 1300, loss: 452758.062500\n",
            "Iteration: 1325, loss: 450623.125000\n",
            "Iteration: 1350, loss: 448536.812500\n",
            "Iteration: 1375, loss: 446612.218750\n",
            "Iteration: 1400, loss: 444672.500000\n",
            "Iteration: 1425, loss: 442931.093750\n",
            "Iteration: 1450, loss: 441197.281250\n",
            "Iteration: 1475, loss: 439608.968750\n",
            "Iteration: 1500, loss: 437952.531250\n",
            "Iteration: 1525, loss: 436432.625000\n",
            "Iteration: 1550, loss: 435034.968750\n",
            "Iteration: 1575, loss: 433609.187500\n",
            "Iteration: 1600, loss: 432266.656250\n",
            "Iteration: 1625, loss: 430924.406250\n",
            "Iteration: 1650, loss: 429594.000000\n",
            "Iteration: 1675, loss: 428388.562500\n",
            "Iteration: 1700, loss: 427254.968750\n",
            "Iteration: 1725, loss: 426000.250000\n",
            "Iteration: 1750, loss: 424918.937500\n",
            "Iteration: 1775, loss: 423885.968750\n",
            "Iteration: 1800, loss: 422773.187500\n",
            "Iteration: 1825, loss: 421722.875000\n",
            "Iteration: 1850, loss: 420703.531250\n",
            "Iteration: 1875, loss: 419724.343750\n",
            "Iteration: 1900, loss: 418710.968750\n",
            "Iteration: 1925, loss: 417713.875000\n",
            "Iteration: 1950, loss: 416744.812500\n",
            "Iteration: 1975, loss: 415803.187500\n",
            "Iteration: 2000, loss: 414914.906250\n",
            "Iteration: 25, loss: 24544258.000000\n",
            "Iteration: 50, loss: 3152124.500000\n",
            "Iteration: 75, loss: 1612245.750000\n",
            "Iteration: 100, loss: 1085901.500000\n",
            "Iteration: 125, loss: 829211.312500\n",
            "Iteration: 150, loss: 691539.875000\n",
            "Iteration: 175, loss: 601481.187500\n",
            "Iteration: 200, loss: 531514.687500\n",
            "Iteration: 225, loss: 481120.093750\n",
            "Iteration: 250, loss: 442413.625000\n",
            "Iteration: 275, loss: 413375.968750\n",
            "Iteration: 300, loss: 390906.531250\n",
            "Iteration: 325, loss: 374166.343750\n",
            "Iteration: 350, loss: 360484.781250\n",
            "Iteration: 375, loss: 349456.218750\n",
            "Iteration: 400, loss: 340414.531250\n",
            "Iteration: 425, loss: 333215.843750\n",
            "Iteration: 450, loss: 326895.687500\n",
            "Iteration: 475, loss: 321657.531250\n",
            "Iteration: 500, loss: 316682.937500\n",
            "Iteration: 525, loss: 312405.906250\n",
            "Iteration: 550, loss: 308539.562500\n",
            "Iteration: 575, loss: 305256.562500\n",
            "Iteration: 600, loss: 302265.093750\n",
            "Iteration: 625, loss: 299350.031250\n",
            "Iteration: 650, loss: 296868.781250\n",
            "Iteration: 675, loss: 294525.125000\n",
            "Iteration: 700, loss: 292409.343750\n",
            "Iteration: 725, loss: 290479.562500\n",
            "Iteration: 750, loss: 288876.687500\n",
            "Iteration: 775, loss: 287234.968750\n",
            "Iteration: 800, loss: 285778.093750\n",
            "Iteration: 825, loss: 284358.531250\n",
            "Iteration: 850, loss: 283036.468750\n",
            "Iteration: 875, loss: 281786.781250\n",
            "Iteration: 900, loss: 280645.500000\n",
            "Iteration: 925, loss: 279581.937500\n",
            "Iteration: 950, loss: 278625.437500\n",
            "Iteration: 975, loss: 277709.531250\n",
            "Iteration: 1000, loss: 276775.093750\n",
            "Iteration: 1025, loss: 275892.593750\n",
            "Iteration: 1050, loss: 275068.656250\n",
            "Iteration: 1075, loss: 274329.937500\n",
            "Iteration: 1100, loss: 273596.187500\n",
            "Iteration: 1125, loss: 272871.906250\n",
            "Iteration: 1150, loss: 272195.000000\n",
            "Iteration: 1175, loss: 271558.687500\n",
            "Iteration: 1200, loss: 270932.468750\n",
            "Iteration: 1225, loss: 270335.937500\n",
            "Iteration: 1250, loss: 269728.000000\n",
            "Iteration: 1275, loss: 269146.187500\n",
            "Iteration: 1300, loss: 268680.718750\n",
            "Iteration: 1325, loss: 268197.687500\n",
            "Iteration: 1350, loss: 267721.656250\n",
            "Iteration: 1375, loss: 267265.187500\n",
            "Iteration: 1400, loss: 266814.281250\n",
            "Iteration: 1425, loss: 266365.156250\n",
            "Iteration: 1450, loss: 265928.812500\n",
            "Iteration: 1475, loss: 265528.968750\n",
            "Iteration: 1500, loss: 265144.156250\n",
            "Iteration: 1525, loss: 264777.593750\n",
            "Iteration: 1550, loss: 264416.156250\n",
            "Iteration: 1575, loss: 264068.343750\n",
            "Iteration: 1600, loss: 263769.125000\n",
            "Iteration: 1625, loss: 263453.625000\n",
            "Iteration: 1650, loss: 263176.687500\n",
            "Iteration: 1675, loss: 262848.656250\n",
            "Iteration: 1700, loss: 262559.250000\n",
            "Iteration: 1725, loss: 262300.281250\n",
            "Iteration: 1750, loss: 262013.968750\n",
            "Iteration: 1775, loss: 261750.109375\n",
            "Iteration: 1800, loss: 261504.343750\n",
            "Iteration: 1825, loss: 261275.484375\n",
            "Iteration: 1850, loss: 261022.156250\n",
            "Iteration: 1875, loss: 260786.406250\n",
            "Iteration: 1900, loss: 260586.562500\n",
            "Iteration: 1925, loss: 260387.375000\n",
            "Iteration: 1950, loss: 260179.406250\n",
            "Iteration: 1975, loss: 259963.671875\n",
            "Iteration: 2000, loss: 259777.265625\n"
          ]
        }
      ],
      "source": [
        "random_losses = []\n",
        "for i in range(len(style_images)):\n",
        "    random_losses.append(run_transfer(style_images[i], content_images[i], \"random\", 2000, 25, output_dir+'random_max_2000/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 703441.437500\n",
            "Iteration: 50, loss: 470482.625000\n",
            "Iteration: 75, loss: 411298.750000\n",
            "Iteration: 100, loss: 379371.593750\n",
            "Iteration: 125, loss: 358262.750000\n",
            "Iteration: 150, loss: 342941.625000\n",
            "Iteration: 175, loss: 331120.656250\n",
            "Iteration: 200, loss: 321678.687500\n",
            "Iteration: 225, loss: 313266.750000\n",
            "Iteration: 250, loss: 306771.812500\n",
            "Iteration: 275, loss: 300824.812500\n",
            "Iteration: 300, loss: 295892.656250\n",
            "Iteration: 325, loss: 291571.687500\n",
            "Iteration: 350, loss: 287650.000000\n",
            "Iteration: 375, loss: 284105.062500\n",
            "Iteration: 400, loss: 280975.218750\n",
            "Iteration: 425, loss: 278043.781250\n",
            "Iteration: 450, loss: 275441.343750\n",
            "Iteration: 475, loss: 273025.593750\n",
            "Iteration: 500, loss: 270783.312500\n",
            "Iteration: 525, loss: 268656.187500\n",
            "Iteration: 550, loss: 266745.468750\n",
            "Iteration: 575, loss: 265037.812500\n",
            "Iteration: 600, loss: 263395.125000\n",
            "Iteration: 625, loss: 261827.609375\n",
            "Iteration: 650, loss: 260395.875000\n",
            "Iteration: 675, loss: 259085.093750\n",
            "Iteration: 700, loss: 257895.187500\n",
            "Iteration: 725, loss: 256715.453125\n",
            "Iteration: 750, loss: 255632.671875\n",
            "Iteration: 775, loss: 254586.156250\n",
            "Iteration: 800, loss: 253641.609375\n",
            "Iteration: 825, loss: 252698.312500\n",
            "Iteration: 850, loss: 251918.625000\n",
            "Iteration: 875, loss: 251054.890625\n",
            "Iteration: 900, loss: 250278.312500\n",
            "Iteration: 925, loss: 249494.562500\n",
            "Iteration: 950, loss: 248780.859375\n",
            "Iteration: 975, loss: 248101.953125\n",
            "Iteration: 1000, loss: 247456.531250\n",
            "Iteration: 1025, loss: 246879.734375\n",
            "Iteration: 1050, loss: 246267.765625\n",
            "Iteration: 1075, loss: 245709.250000\n",
            "Iteration: 1100, loss: 245185.000000\n",
            "Iteration: 1125, loss: 244715.828125\n",
            "Iteration: 1150, loss: 244207.328125\n",
            "Iteration: 1175, loss: 243720.828125\n",
            "Iteration: 1200, loss: 243261.625000\n",
            "Iteration: 1225, loss: 242811.750000\n",
            "Iteration: 1250, loss: 242382.484375\n",
            "Iteration: 1275, loss: 241930.062500\n",
            "Iteration: 1300, loss: 241537.546875\n",
            "Iteration: 1325, loss: 241165.328125\n",
            "Iteration: 1350, loss: 240787.281250\n",
            "Iteration: 1375, loss: 240386.546875\n",
            "Iteration: 1400, loss: 240012.843750\n",
            "Iteration: 1425, loss: 239672.281250\n",
            "Iteration: 1450, loss: 239354.187500\n",
            "Iteration: 1475, loss: 239047.484375\n",
            "Iteration: 1500, loss: 238750.593750\n",
            "Iteration: 1525, loss: 238457.531250\n",
            "Iteration: 1550, loss: 238164.593750\n",
            "Iteration: 1575, loss: 237879.515625\n",
            "Iteration: 1600, loss: 237606.359375\n",
            "Iteration: 1625, loss: 237366.156250\n",
            "Iteration: 1650, loss: 237106.484375\n",
            "Iteration: 1675, loss: 236849.359375\n",
            "Iteration: 1700, loss: 236584.609375\n",
            "Iteration: 1725, loss: 236339.078125\n",
            "Iteration: 1750, loss: 236085.468750\n",
            "Iteration: 1775, loss: 235859.593750\n",
            "Iteration: 1800, loss: 235630.328125\n",
            "Iteration: 1825, loss: 235423.125000\n",
            "Iteration: 1850, loss: 235201.890625\n",
            "Iteration: 1875, loss: 234997.156250\n",
            "Iteration: 1900, loss: 234779.875000\n",
            "Iteration: 1925, loss: 234585.984375\n",
            "Iteration: 1950, loss: 234393.062500\n",
            "Iteration: 1975, loss: 234186.812500\n",
            "Iteration: 2000, loss: 233978.421875\n",
            "Iteration: 25, loss: 503714.562500\n",
            "Iteration: 50, loss: 372345.781250\n",
            "Iteration: 75, loss: 323711.000000\n",
            "Iteration: 100, loss: 296385.468750\n",
            "Iteration: 125, loss: 275616.375000\n",
            "Iteration: 150, loss: 261243.203125\n",
            "Iteration: 175, loss: 248939.718750\n",
            "Iteration: 200, loss: 239720.453125\n",
            "Iteration: 225, loss: 232031.000000\n",
            "Iteration: 250, loss: 225449.421875\n",
            "Iteration: 275, loss: 219665.359375\n",
            "Iteration: 300, loss: 214323.671875\n",
            "Iteration: 325, loss: 209814.781250\n",
            "Iteration: 350, loss: 205399.296875\n",
            "Iteration: 375, loss: 201354.515625\n",
            "Iteration: 400, loss: 197767.734375\n",
            "Iteration: 425, loss: 194502.218750\n",
            "Iteration: 450, loss: 191645.593750\n",
            "Iteration: 475, loss: 188727.796875\n",
            "Iteration: 500, loss: 185925.734375\n",
            "Iteration: 525, loss: 183287.031250\n",
            "Iteration: 550, loss: 180807.312500\n",
            "Iteration: 575, loss: 178548.328125\n",
            "Iteration: 600, loss: 176436.265625\n",
            "Iteration: 625, loss: 174479.265625\n",
            "Iteration: 650, loss: 172704.718750\n",
            "Iteration: 675, loss: 170963.078125\n",
            "Iteration: 700, loss: 169363.546875\n",
            "Iteration: 725, loss: 167891.921875\n",
            "Iteration: 750, loss: 166506.250000\n",
            "Iteration: 775, loss: 165140.453125\n",
            "Iteration: 800, loss: 163810.906250\n",
            "Iteration: 825, loss: 162577.000000\n",
            "Iteration: 850, loss: 161452.437500\n",
            "Iteration: 875, loss: 160321.031250\n",
            "Iteration: 900, loss: 159190.187500\n",
            "Iteration: 925, loss: 158094.468750\n",
            "Iteration: 950, loss: 157142.562500\n",
            "Iteration: 975, loss: 156190.375000\n",
            "Iteration: 1000, loss: 155277.375000\n",
            "Iteration: 1025, loss: 154499.406250\n",
            "Iteration: 1050, loss: 153708.703125\n",
            "Iteration: 1075, loss: 153002.703125\n",
            "Iteration: 1100, loss: 152241.156250\n",
            "Iteration: 1125, loss: 151590.281250\n",
            "Iteration: 1150, loss: 150902.031250\n",
            "Iteration: 1175, loss: 150278.328125\n",
            "Iteration: 1200, loss: 149684.109375\n",
            "Iteration: 1225, loss: 149039.843750\n",
            "Iteration: 1250, loss: 148478.734375\n",
            "Iteration: 1275, loss: 147966.187500\n",
            "Iteration: 1300, loss: 147450.562500\n",
            "Iteration: 1325, loss: 146932.453125\n",
            "Iteration: 1350, loss: 146405.281250\n",
            "Iteration: 1375, loss: 145967.781250\n",
            "Iteration: 1400, loss: 145566.828125\n",
            "Iteration: 1425, loss: 145127.000000\n",
            "Iteration: 1450, loss: 144685.937500\n",
            "Iteration: 1475, loss: 144280.859375\n",
            "Iteration: 1500, loss: 143929.890625\n",
            "Iteration: 1525, loss: 143570.312500\n",
            "Iteration: 1550, loss: 143199.921875\n",
            "Iteration: 1575, loss: 142852.171875\n",
            "Iteration: 1600, loss: 142514.156250\n",
            "Iteration: 1625, loss: 142158.937500\n",
            "Iteration: 1650, loss: 141838.750000\n",
            "Iteration: 1675, loss: 141543.875000\n",
            "Iteration: 1700, loss: 141237.468750\n",
            "Iteration: 1725, loss: 140942.156250\n",
            "Iteration: 1750, loss: 140666.187500\n",
            "Iteration: 1775, loss: 140418.218750\n",
            "Iteration: 1800, loss: 140162.359375\n",
            "Iteration: 1825, loss: 139933.765625\n",
            "Iteration: 1850, loss: 139678.906250\n",
            "Iteration: 1875, loss: 139441.937500\n",
            "Iteration: 1900, loss: 139214.453125\n",
            "Iteration: 1925, loss: 139001.234375\n",
            "Iteration: 1950, loss: 138771.234375\n",
            "Iteration: 1975, loss: 138548.015625\n",
            "Iteration: 2000, loss: 138343.281250\n",
            "Iteration: 25, loss: 2540493.000000\n",
            "Iteration: 50, loss: 1349578.500000\n",
            "Iteration: 75, loss: 1076018.000000\n",
            "Iteration: 100, loss: 962974.625000\n",
            "Iteration: 125, loss: 896993.250000\n",
            "Iteration: 150, loss: 855628.937500\n",
            "Iteration: 175, loss: 828463.750000\n",
            "Iteration: 200, loss: 805396.500000\n",
            "Iteration: 225, loss: 787199.687500\n",
            "Iteration: 250, loss: 771530.562500\n",
            "Iteration: 275, loss: 758573.875000\n",
            "Iteration: 300, loss: 746407.437500\n",
            "Iteration: 325, loss: 736817.562500\n",
            "Iteration: 350, loss: 727733.187500\n",
            "Iteration: 375, loss: 719610.375000\n",
            "Iteration: 400, loss: 712424.125000\n",
            "Iteration: 425, loss: 705737.750000\n",
            "Iteration: 450, loss: 699988.125000\n",
            "Iteration: 475, loss: 694502.500000\n",
            "Iteration: 500, loss: 689513.187500\n",
            "Iteration: 525, loss: 684858.062500\n",
            "Iteration: 550, loss: 680443.187500\n",
            "Iteration: 575, loss: 676691.437500\n",
            "Iteration: 600, loss: 673051.437500\n",
            "Iteration: 625, loss: 669521.187500\n",
            "Iteration: 650, loss: 666140.187500\n",
            "Iteration: 675, loss: 662996.312500\n",
            "Iteration: 700, loss: 659982.375000\n",
            "Iteration: 725, loss: 657244.562500\n",
            "Iteration: 750, loss: 654519.937500\n",
            "Iteration: 775, loss: 651896.812500\n",
            "Iteration: 800, loss: 649498.125000\n",
            "Iteration: 825, loss: 647193.312500\n",
            "Iteration: 850, loss: 645024.062500\n",
            "Iteration: 875, loss: 642827.437500\n",
            "Iteration: 900, loss: 640745.937500\n",
            "Iteration: 925, loss: 638902.250000\n",
            "Iteration: 950, loss: 637029.500000\n",
            "Iteration: 975, loss: 635277.437500\n",
            "Iteration: 1000, loss: 633563.062500\n",
            "Iteration: 1025, loss: 631920.000000\n",
            "Iteration: 1050, loss: 630344.312500\n",
            "Iteration: 1075, loss: 628704.125000\n",
            "Iteration: 1100, loss: 627127.937500\n",
            "Iteration: 1125, loss: 625704.812500\n",
            "Iteration: 1150, loss: 624170.250000\n",
            "Iteration: 1175, loss: 622808.500000\n",
            "Iteration: 1200, loss: 621402.750000\n",
            "Iteration: 1225, loss: 620118.500000\n",
            "Iteration: 1250, loss: 618840.312500\n",
            "Iteration: 1275, loss: 617511.187500\n",
            "Iteration: 1300, loss: 616252.125000\n",
            "Iteration: 1325, loss: 614945.437500\n",
            "Iteration: 1350, loss: 613755.500000\n",
            "Iteration: 1375, loss: 612547.375000\n",
            "Iteration: 1400, loss: 611283.500000\n",
            "Iteration: 1425, loss: 610138.187500\n",
            "Iteration: 1450, loss: 608879.937500\n",
            "Iteration: 1475, loss: 607659.937500\n",
            "Iteration: 1500, loss: 606620.875000\n",
            "Iteration: 1525, loss: 605485.000000\n",
            "Iteration: 1550, loss: 604392.437500\n",
            "Iteration: 1575, loss: 603354.750000\n",
            "Iteration: 1600, loss: 602345.875000\n",
            "Iteration: 1625, loss: 601258.187500\n",
            "Iteration: 1650, loss: 600222.000000\n",
            "Iteration: 1675, loss: 599195.125000\n",
            "Iteration: 1700, loss: 598197.625000\n",
            "Iteration: 1725, loss: 597222.125000\n",
            "Iteration: 1750, loss: 596284.062500\n",
            "Iteration: 1775, loss: 595349.437500\n",
            "Iteration: 1800, loss: 594540.312500\n",
            "Iteration: 1825, loss: 593684.562500\n",
            "Iteration: 1850, loss: 592830.875000\n",
            "Iteration: 1875, loss: 592052.750000\n",
            "Iteration: 1900, loss: 591236.750000\n",
            "Iteration: 1925, loss: 590431.875000\n",
            "Iteration: 1950, loss: 589661.562500\n",
            "Iteration: 1975, loss: 588857.250000\n",
            "Iteration: 2000, loss: 588124.687500\n",
            "Iteration: 25, loss: 2147428.500000\n",
            "Iteration: 50, loss: 995201.250000\n",
            "Iteration: 75, loss: 711209.875000\n",
            "Iteration: 100, loss: 603277.812500\n",
            "Iteration: 125, loss: 548326.125000\n",
            "Iteration: 150, loss: 516814.312500\n",
            "Iteration: 175, loss: 487695.937500\n",
            "Iteration: 200, loss: 464892.093750\n",
            "Iteration: 225, loss: 448940.500000\n",
            "Iteration: 250, loss: 435451.750000\n",
            "Iteration: 275, loss: 424001.906250\n",
            "Iteration: 300, loss: 414011.500000\n",
            "Iteration: 325, loss: 405080.750000\n",
            "Iteration: 350, loss: 397866.093750\n",
            "Iteration: 375, loss: 391339.437500\n",
            "Iteration: 400, loss: 385769.468750\n",
            "Iteration: 425, loss: 380087.437500\n",
            "Iteration: 450, loss: 375327.031250\n",
            "Iteration: 475, loss: 370447.437500\n",
            "Iteration: 500, loss: 366315.937500\n",
            "Iteration: 525, loss: 362535.250000\n",
            "Iteration: 550, loss: 358893.375000\n",
            "Iteration: 575, loss: 355453.968750\n",
            "Iteration: 600, loss: 352348.625000\n",
            "Iteration: 625, loss: 349348.625000\n",
            "Iteration: 650, loss: 346533.656250\n",
            "Iteration: 675, loss: 343841.437500\n",
            "Iteration: 700, loss: 341216.375000\n",
            "Iteration: 725, loss: 338846.593750\n",
            "Iteration: 750, loss: 336487.093750\n",
            "Iteration: 775, loss: 334383.312500\n",
            "Iteration: 800, loss: 332255.937500\n",
            "Iteration: 825, loss: 330296.031250\n",
            "Iteration: 850, loss: 328354.250000\n",
            "Iteration: 875, loss: 326599.093750\n",
            "Iteration: 900, loss: 324839.906250\n",
            "Iteration: 925, loss: 323081.906250\n",
            "Iteration: 950, loss: 321417.437500\n",
            "Iteration: 975, loss: 319814.781250\n",
            "Iteration: 1000, loss: 318318.468750\n",
            "Iteration: 1025, loss: 316986.562500\n",
            "Iteration: 1050, loss: 315590.093750\n",
            "Iteration: 1075, loss: 314329.250000\n",
            "Iteration: 1100, loss: 313052.218750\n",
            "Iteration: 1125, loss: 311827.750000\n",
            "Iteration: 1150, loss: 310719.437500\n",
            "Iteration: 1175, loss: 309642.156250\n",
            "Iteration: 1200, loss: 308535.125000\n",
            "Iteration: 1225, loss: 307545.593750\n",
            "Iteration: 1250, loss: 306524.031250\n",
            "Iteration: 1275, loss: 305605.937500\n",
            "Iteration: 1300, loss: 304769.843750\n",
            "Iteration: 1325, loss: 303847.187500\n",
            "Iteration: 1350, loss: 303019.375000\n",
            "Iteration: 1375, loss: 302217.968750\n",
            "Iteration: 1400, loss: 301411.125000\n",
            "Iteration: 1425, loss: 300642.968750\n",
            "Iteration: 1450, loss: 299892.312500\n",
            "Iteration: 1475, loss: 299234.375000\n",
            "Iteration: 1500, loss: 298558.125000\n",
            "Iteration: 1525, loss: 297886.437500\n",
            "Iteration: 1550, loss: 297263.000000\n",
            "Iteration: 1575, loss: 296642.437500\n",
            "Iteration: 1600, loss: 296036.250000\n",
            "Iteration: 1625, loss: 295489.531250\n",
            "Iteration: 1650, loss: 294921.218750\n",
            "Iteration: 1675, loss: 294387.375000\n",
            "Iteration: 1700, loss: 293815.125000\n",
            "Iteration: 1725, loss: 293244.343750\n",
            "Iteration: 1750, loss: 292693.437500\n",
            "Iteration: 1775, loss: 292197.937500\n",
            "Iteration: 1800, loss: 291746.468750\n",
            "Iteration: 1825, loss: 291254.375000\n",
            "Iteration: 1850, loss: 290744.562500\n",
            "Iteration: 1875, loss: 290276.937500\n",
            "Iteration: 1900, loss: 289822.875000\n",
            "Iteration: 1925, loss: 289414.468750\n",
            "Iteration: 1950, loss: 288961.812500\n",
            "Iteration: 1975, loss: 288560.906250\n",
            "Iteration: 2000, loss: 288152.750000\n",
            "Iteration: 25, loss: 1203741.000000\n",
            "Iteration: 50, loss: 737503.437500\n",
            "Iteration: 75, loss: 645763.062500\n",
            "Iteration: 100, loss: 604070.937500\n",
            "Iteration: 125, loss: 578606.875000\n",
            "Iteration: 150, loss: 560016.062500\n",
            "Iteration: 175, loss: 545237.500000\n",
            "Iteration: 200, loss: 533886.562500\n",
            "Iteration: 225, loss: 523735.687500\n",
            "Iteration: 250, loss: 514955.000000\n",
            "Iteration: 275, loss: 507847.468750\n",
            "Iteration: 300, loss: 501061.687500\n",
            "Iteration: 325, loss: 494910.031250\n",
            "Iteration: 350, loss: 489676.312500\n",
            "Iteration: 375, loss: 484896.312500\n",
            "Iteration: 400, loss: 480395.156250\n",
            "Iteration: 425, loss: 476255.218750\n",
            "Iteration: 450, loss: 472220.500000\n",
            "Iteration: 475, loss: 468761.250000\n",
            "Iteration: 500, loss: 465229.437500\n",
            "Iteration: 525, loss: 462247.343750\n",
            "Iteration: 550, loss: 459274.375000\n",
            "Iteration: 575, loss: 456551.312500\n",
            "Iteration: 600, loss: 453852.656250\n",
            "Iteration: 625, loss: 451476.500000\n",
            "Iteration: 650, loss: 449155.500000\n",
            "Iteration: 675, loss: 446954.718750\n",
            "Iteration: 700, loss: 444904.718750\n",
            "Iteration: 725, loss: 442870.625000\n",
            "Iteration: 750, loss: 440838.468750\n",
            "Iteration: 775, loss: 439021.156250\n",
            "Iteration: 800, loss: 437262.593750\n",
            "Iteration: 825, loss: 435554.437500\n",
            "Iteration: 850, loss: 433885.500000\n",
            "Iteration: 875, loss: 432279.875000\n",
            "Iteration: 900, loss: 430701.625000\n",
            "Iteration: 925, loss: 429303.968750\n",
            "Iteration: 950, loss: 427884.062500\n",
            "Iteration: 975, loss: 426425.656250\n",
            "Iteration: 1000, loss: 425206.468750\n",
            "Iteration: 1025, loss: 424066.812500\n",
            "Iteration: 1050, loss: 422892.125000\n",
            "Iteration: 1075, loss: 421678.562500\n",
            "Iteration: 1100, loss: 420584.187500\n",
            "Iteration: 1125, loss: 419640.968750\n",
            "Iteration: 1150, loss: 418670.468750\n",
            "Iteration: 1175, loss: 417636.906250\n",
            "Iteration: 1200, loss: 416647.468750\n",
            "Iteration: 1225, loss: 415712.343750\n",
            "Iteration: 1250, loss: 414796.125000\n",
            "Iteration: 1275, loss: 413905.000000\n",
            "Iteration: 1300, loss: 412951.375000\n",
            "Iteration: 1325, loss: 412092.375000\n",
            "Iteration: 1350, loss: 411260.437500\n",
            "Iteration: 1375, loss: 410450.343750\n",
            "Iteration: 1400, loss: 409651.500000\n",
            "Iteration: 1425, loss: 408858.343750\n",
            "Iteration: 1450, loss: 408049.468750\n",
            "Iteration: 1475, loss: 407199.000000\n",
            "Iteration: 1500, loss: 406505.531250\n",
            "Iteration: 1525, loss: 405759.625000\n",
            "Iteration: 1550, loss: 405070.250000\n",
            "Iteration: 1575, loss: 404304.062500\n",
            "Iteration: 1600, loss: 403666.625000\n",
            "Iteration: 1625, loss: 403037.500000\n",
            "Iteration: 1650, loss: 402378.687500\n",
            "Iteration: 1675, loss: 401752.343750\n",
            "Iteration: 1700, loss: 401124.218750\n",
            "Iteration: 1725, loss: 400548.250000\n",
            "Iteration: 1750, loss: 400012.906250\n",
            "Iteration: 1775, loss: 399443.875000\n",
            "Iteration: 1800, loss: 398887.593750\n",
            "Iteration: 1825, loss: 398362.781250\n",
            "Iteration: 1850, loss: 397825.156250\n",
            "Iteration: 1875, loss: 397321.218750\n",
            "Iteration: 1900, loss: 396853.437500\n",
            "Iteration: 1925, loss: 396351.000000\n",
            "Iteration: 1950, loss: 395886.281250\n",
            "Iteration: 1975, loss: 395400.843750\n",
            "Iteration: 2000, loss: 394943.156250\n",
            "Iteration: 25, loss: 630311.312500\n",
            "Iteration: 50, loss: 464849.343750\n",
            "Iteration: 75, loss: 415934.281250\n",
            "Iteration: 100, loss: 387037.812500\n",
            "Iteration: 125, loss: 367729.625000\n",
            "Iteration: 150, loss: 353520.531250\n",
            "Iteration: 175, loss: 342866.750000\n",
            "Iteration: 200, loss: 334109.812500\n",
            "Iteration: 225, loss: 326677.968750\n",
            "Iteration: 250, loss: 320695.031250\n",
            "Iteration: 275, loss: 315576.750000\n",
            "Iteration: 300, loss: 311097.531250\n",
            "Iteration: 325, loss: 307149.281250\n",
            "Iteration: 350, loss: 303740.968750\n",
            "Iteration: 375, loss: 300712.406250\n",
            "Iteration: 400, loss: 298040.062500\n",
            "Iteration: 425, loss: 295586.906250\n",
            "Iteration: 450, loss: 293327.437500\n",
            "Iteration: 475, loss: 291300.156250\n",
            "Iteration: 500, loss: 289530.468750\n",
            "Iteration: 525, loss: 287722.937500\n",
            "Iteration: 550, loss: 286083.812500\n",
            "Iteration: 575, loss: 284594.406250\n",
            "Iteration: 600, loss: 283245.406250\n",
            "Iteration: 625, loss: 281965.875000\n",
            "Iteration: 650, loss: 280723.218750\n",
            "Iteration: 675, loss: 279632.375000\n",
            "Iteration: 700, loss: 278537.781250\n",
            "Iteration: 725, loss: 277537.937500\n",
            "Iteration: 750, loss: 276561.750000\n",
            "Iteration: 775, loss: 275704.468750\n",
            "Iteration: 800, loss: 274852.031250\n",
            "Iteration: 825, loss: 274017.656250\n",
            "Iteration: 850, loss: 273274.875000\n",
            "Iteration: 875, loss: 272602.875000\n",
            "Iteration: 900, loss: 271952.843750\n",
            "Iteration: 925, loss: 271308.750000\n",
            "Iteration: 950, loss: 270658.156250\n",
            "Iteration: 975, loss: 270105.750000\n",
            "Iteration: 1000, loss: 269565.937500\n",
            "Iteration: 1025, loss: 269030.125000\n",
            "Iteration: 1050, loss: 268519.187500\n",
            "Iteration: 1075, loss: 268048.000000\n",
            "Iteration: 1100, loss: 267588.656250\n",
            "Iteration: 1125, loss: 267154.968750\n",
            "Iteration: 1150, loss: 266705.125000\n",
            "Iteration: 1175, loss: 266279.406250\n",
            "Iteration: 1200, loss: 265898.031250\n",
            "Iteration: 1225, loss: 265515.281250\n",
            "Iteration: 1250, loss: 265142.437500\n",
            "Iteration: 1275, loss: 264790.000000\n",
            "Iteration: 1300, loss: 264467.937500\n",
            "Iteration: 1325, loss: 264168.468750\n",
            "Iteration: 1350, loss: 263842.281250\n",
            "Iteration: 1375, loss: 263519.937500\n",
            "Iteration: 1400, loss: 263254.656250\n",
            "Iteration: 1425, loss: 262959.531250\n",
            "Iteration: 1450, loss: 262665.281250\n",
            "Iteration: 1475, loss: 262382.687500\n",
            "Iteration: 1500, loss: 262077.515625\n",
            "Iteration: 1525, loss: 261838.296875\n",
            "Iteration: 1550, loss: 261594.750000\n",
            "Iteration: 1575, loss: 261350.390625\n",
            "Iteration: 1600, loss: 261100.093750\n",
            "Iteration: 1625, loss: 260882.406250\n",
            "Iteration: 1650, loss: 260678.546875\n",
            "Iteration: 1675, loss: 260485.734375\n",
            "Iteration: 1700, loss: 260298.390625\n",
            "Iteration: 1725, loss: 260103.125000\n",
            "Iteration: 1750, loss: 259913.375000\n",
            "Iteration: 1775, loss: 259733.968750\n",
            "Iteration: 1800, loss: 259561.031250\n",
            "Iteration: 1825, loss: 259383.578125\n",
            "Iteration: 1850, loss: 259221.718750\n",
            "Iteration: 1875, loss: 259048.562500\n",
            "Iteration: 1900, loss: 258883.781250\n",
            "Iteration: 1925, loss: 258724.421875\n",
            "Iteration: 1950, loss: 258561.593750\n",
            "Iteration: 1975, loss: 258408.906250\n",
            "Iteration: 2000, loss: 258277.578125\n"
          ]
        }
      ],
      "source": [
        "style_losses = []\n",
        "for i in range(len(style_images)):\n",
        "    style_losses.append(run_transfer(style_images[i], content_images[i], \"style\", 2000, 25, output_dir+'style_max_2000/'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "content_losses_np = np.array(content_losses)\n",
        "random_losses_np = np.array(random_losses)\n",
        "style_losses_np = np.array(style_losses)\n",
        "\n",
        "np.savetxt(output_dir+\"content_max_losses.csv\", content_losses_np, delimiter=\",\")\n",
        "np.savetxt(output_dir+\"random_max_losses.csv\", random_losses_np, delimiter=\",\")\n",
        "np.savetxt(output_dir+\"style_max_losses.csv\", style_losses_np, delimiter=\",\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "content_losses_np = np.genfromtxt(output_dir+\"content_max_losses.csv\", delimiter=\",\")\n",
        "random_losses_np = np.genfromtxt(output_dir+\"random_max_losses.csv\", delimiter=\",\")\n",
        "style_losses_np = np.genfromtxt(output_dir+\"style_max_losses.csv\", delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=[10,6])\n",
        "plt.plot(range(0, 2000, 25), np.log(content_losses_np.mean(axis=0)), color = \"blue\")\n",
        "plt.plot(range(0, 2000, 25), np.log(random_losses_np.mean(axis=0)), color = \"orange\")\n",
        "plt.plot(range(0, 2000, 25), np.log(style_losses_np.mean(axis=0)), color = \"red\")\n",
        "plt.legend(labels = [\"Content\", \"Random\", \"Style\"], loc = \"upper right\")\n",
        "plt.xlabel(\"number of epochs\")\n",
        "plt.ylabel(\"average total loss\")\n",
        "plt.title(\"Log Average Total Loss vs. Number of Epochs (Avg Pooling)\")\n",
        "plt.draw()\n",
        "plt.ioff()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 5146154.000000\n",
            "Iteration: 50, loss: 2282365.500000\n",
            "Iteration: 75, loss: 1170959.250000\n",
            "Iteration: 100, loss: 801498.625000\n",
            "Iteration: 125, loss: 640999.250000\n",
            "Iteration: 150, loss: 532080.437500\n",
            "Iteration: 175, loss: 467222.593750\n",
            "Iteration: 200, loss: 418604.562500\n",
            "Iteration: 225, loss: 382422.000000\n",
            "Iteration: 250, loss: 355251.250000\n",
            "Iteration: 275, loss: 333255.312500\n",
            "Iteration: 300, loss: 318095.406250\n",
            "Iteration: 325, loss: 305607.468750\n",
            "Iteration: 350, loss: 294931.562500\n",
            "Iteration: 375, loss: 286599.093750\n",
            "Iteration: 400, loss: 279814.906250\n",
            "Iteration: 425, loss: 274232.593750\n",
            "Iteration: 450, loss: 269569.406250\n",
            "Iteration: 475, loss: 265467.125000\n",
            "Iteration: 500, loss: 261876.671875\n",
            "Iteration: 525, loss: 259110.046875\n",
            "Iteration: 550, loss: 256398.171875\n",
            "Iteration: 575, loss: 253881.015625\n",
            "Iteration: 600, loss: 251727.265625\n",
            "Iteration: 625, loss: 249885.562500\n",
            "Iteration: 650, loss: 248141.437500\n",
            "Iteration: 675, loss: 246626.437500\n",
            "Iteration: 700, loss: 245223.656250\n",
            "Iteration: 725, loss: 243936.734375\n",
            "Iteration: 750, loss: 242853.531250\n",
            "Iteration: 775, loss: 241784.562500\n",
            "Iteration: 800, loss: 240759.531250\n",
            "Iteration: 825, loss: 239861.312500\n",
            "Iteration: 850, loss: 239024.000000\n",
            "Iteration: 875, loss: 238219.937500\n",
            "Iteration: 900, loss: 237457.031250\n",
            "Iteration: 925, loss: 236751.984375\n",
            "Iteration: 950, loss: 236087.765625\n",
            "Iteration: 975, loss: 235444.156250\n",
            "Iteration: 1000, loss: 234873.421875\n",
            "Iteration: 25, loss: 5113155.000000\n",
            "Iteration: 50, loss: 2677554.500000\n",
            "Iteration: 75, loss: 1727524.250000\n",
            "Iteration: 100, loss: 1176378.000000\n",
            "Iteration: 125, loss: 835857.750000\n",
            "Iteration: 150, loss: 613436.750000\n",
            "Iteration: 175, loss: 475369.937500\n",
            "Iteration: 200, loss: 383369.031250\n",
            "Iteration: 225, loss: 323133.406250\n",
            "Iteration: 250, loss: 279101.250000\n",
            "Iteration: 275, loss: 248542.140625\n",
            "Iteration: 300, loss: 227450.218750\n",
            "Iteration: 325, loss: 211099.781250\n",
            "Iteration: 350, loss: 198813.546875\n",
            "Iteration: 375, loss: 189334.562500\n",
            "Iteration: 400, loss: 181732.171875\n",
            "Iteration: 425, loss: 175808.093750\n",
            "Iteration: 450, loss: 171003.796875\n",
            "Iteration: 475, loss: 166897.015625\n",
            "Iteration: 500, loss: 163603.875000\n",
            "Iteration: 525, loss: 160831.390625\n",
            "Iteration: 550, loss: 158354.109375\n",
            "Iteration: 575, loss: 156077.875000\n",
            "Iteration: 600, loss: 153978.187500\n",
            "Iteration: 625, loss: 152123.187500\n",
            "Iteration: 650, loss: 150508.062500\n",
            "Iteration: 675, loss: 149011.062500\n",
            "Iteration: 700, loss: 147667.328125\n",
            "Iteration: 725, loss: 146363.156250\n",
            "Iteration: 750, loss: 145324.937500\n",
            "Iteration: 775, loss: 144380.265625\n",
            "Iteration: 800, loss: 143432.609375\n",
            "Iteration: 825, loss: 142539.593750\n",
            "Iteration: 850, loss: 141812.687500\n",
            "Iteration: 875, loss: 141081.671875\n",
            "Iteration: 900, loss: 140415.250000\n",
            "Iteration: 925, loss: 139776.906250\n",
            "Iteration: 950, loss: 139216.562500\n",
            "Iteration: 975, loss: 138670.015625\n",
            "Iteration: 1000, loss: 138169.968750\n",
            "Iteration: 25, loss: 17679144.000000\n",
            "Iteration: 50, loss: 7143254.000000\n",
            "Iteration: 75, loss: 4465569.500000\n",
            "Iteration: 100, loss: 3202468.000000\n",
            "Iteration: 125, loss: 2504872.750000\n",
            "Iteration: 150, loss: 2008498.125000\n",
            "Iteration: 175, loss: 1688929.750000\n",
            "Iteration: 200, loss: 1453006.000000\n",
            "Iteration: 225, loss: 1281951.125000\n",
            "Iteration: 250, loss: 1151664.000000\n",
            "Iteration: 275, loss: 1052335.375000\n",
            "Iteration: 300, loss: 974267.000000\n",
            "Iteration: 325, loss: 910657.125000\n",
            "Iteration: 350, loss: 860544.750000\n",
            "Iteration: 375, loss: 818346.125000\n",
            "Iteration: 400, loss: 781659.125000\n",
            "Iteration: 425, loss: 752984.500000\n",
            "Iteration: 450, loss: 726732.125000\n",
            "Iteration: 475, loss: 706883.875000\n",
            "Iteration: 500, loss: 686642.500000\n",
            "Iteration: 525, loss: 670236.375000\n",
            "Iteration: 550, loss: 655943.000000\n",
            "Iteration: 575, loss: 643185.375000\n",
            "Iteration: 600, loss: 631846.437500\n",
            "Iteration: 625, loss: 622243.812500\n",
            "Iteration: 650, loss: 613489.875000\n",
            "Iteration: 675, loss: 605579.000000\n",
            "Iteration: 700, loss: 598993.812500\n",
            "Iteration: 725, loss: 592664.000000\n",
            "Iteration: 750, loss: 586917.125000\n",
            "Iteration: 775, loss: 581932.250000\n",
            "Iteration: 800, loss: 577136.375000\n",
            "Iteration: 825, loss: 572555.312500\n",
            "Iteration: 850, loss: 568390.437500\n",
            "Iteration: 875, loss: 564606.625000\n",
            "Iteration: 900, loss: 561331.937500\n",
            "Iteration: 925, loss: 558176.375000\n",
            "Iteration: 950, loss: 555048.312500\n",
            "Iteration: 975, loss: 552244.375000\n",
            "Iteration: 1000, loss: 549693.875000\n",
            "Iteration: 25, loss: 9969392.000000\n",
            "Iteration: 50, loss: 3971228.000000\n",
            "Iteration: 75, loss: 2374230.500000\n",
            "Iteration: 100, loss: 1694212.750000\n",
            "Iteration: 125, loss: 1283870.750000\n",
            "Iteration: 150, loss: 1020993.000000\n",
            "Iteration: 175, loss: 837567.500000\n",
            "Iteration: 200, loss: 717223.375000\n",
            "Iteration: 225, loss: 630291.250000\n",
            "Iteration: 250, loss: 565147.625000\n",
            "Iteration: 275, loss: 517749.312500\n",
            "Iteration: 300, loss: 482802.218750\n",
            "Iteration: 325, loss: 455177.031250\n",
            "Iteration: 350, loss: 432558.031250\n",
            "Iteration: 375, loss: 414505.000000\n",
            "Iteration: 400, loss: 399873.437500\n",
            "Iteration: 425, loss: 387576.500000\n",
            "Iteration: 450, loss: 376885.062500\n",
            "Iteration: 475, loss: 367701.937500\n",
            "Iteration: 500, loss: 359555.375000\n",
            "Iteration: 525, loss: 352069.281250\n",
            "Iteration: 550, loss: 345464.781250\n",
            "Iteration: 575, loss: 339221.281250\n",
            "Iteration: 600, loss: 334104.937500\n",
            "Iteration: 625, loss: 329253.906250\n",
            "Iteration: 650, loss: 325009.906250\n",
            "Iteration: 675, loss: 321039.406250\n",
            "Iteration: 700, loss: 317412.968750\n",
            "Iteration: 725, loss: 313906.218750\n",
            "Iteration: 750, loss: 310932.062500\n",
            "Iteration: 775, loss: 308042.500000\n",
            "Iteration: 800, loss: 305463.906250\n",
            "Iteration: 825, loss: 302937.062500\n",
            "Iteration: 850, loss: 300635.593750\n",
            "Iteration: 875, loss: 298595.343750\n",
            "Iteration: 900, loss: 296717.312500\n",
            "Iteration: 925, loss: 294903.250000\n",
            "Iteration: 950, loss: 293146.875000\n",
            "Iteration: 975, loss: 291623.125000\n",
            "Iteration: 1000, loss: 290171.437500\n",
            "Iteration: 25, loss: 3749850.250000\n",
            "Iteration: 50, loss: 1709365.250000\n",
            "Iteration: 75, loss: 1189127.625000\n",
            "Iteration: 100, loss: 947001.187500\n",
            "Iteration: 125, loss: 803845.625000\n",
            "Iteration: 150, loss: 711963.125000\n",
            "Iteration: 175, loss: 646746.375000\n",
            "Iteration: 200, loss: 597454.750000\n",
            "Iteration: 225, loss: 559416.500000\n",
            "Iteration: 250, loss: 530277.562500\n",
            "Iteration: 275, loss: 507613.125000\n",
            "Iteration: 300, loss: 488926.625000\n",
            "Iteration: 325, loss: 474064.843750\n",
            "Iteration: 350, loss: 461286.312500\n",
            "Iteration: 375, loss: 450953.156250\n",
            "Iteration: 400, loss: 441953.937500\n",
            "Iteration: 425, loss: 434038.625000\n",
            "Iteration: 450, loss: 427112.906250\n",
            "Iteration: 475, loss: 421119.562500\n",
            "Iteration: 500, loss: 415699.250000\n",
            "Iteration: 525, loss: 411025.718750\n",
            "Iteration: 550, loss: 406827.500000\n",
            "Iteration: 575, loss: 402878.937500\n",
            "Iteration: 600, loss: 399303.875000\n",
            "Iteration: 625, loss: 396166.156250\n",
            "Iteration: 650, loss: 393044.406250\n",
            "Iteration: 675, loss: 390299.000000\n",
            "Iteration: 700, loss: 387691.562500\n",
            "Iteration: 725, loss: 385251.812500\n",
            "Iteration: 750, loss: 382913.812500\n",
            "Iteration: 775, loss: 380629.437500\n",
            "Iteration: 800, loss: 378535.968750\n",
            "Iteration: 825, loss: 376686.593750\n",
            "Iteration: 850, loss: 374852.312500\n",
            "Iteration: 875, loss: 373173.312500\n",
            "Iteration: 900, loss: 371647.812500\n",
            "Iteration: 925, loss: 370274.437500\n",
            "Iteration: 950, loss: 368950.031250\n",
            "Iteration: 975, loss: 367682.437500\n",
            "Iteration: 1000, loss: 366513.531250\n",
            "Iteration: 25, loss: 20695720.000000\n",
            "Iteration: 50, loss: 7030687.000000\n",
            "Iteration: 75, loss: 3940703.250000\n",
            "Iteration: 100, loss: 2171182.000000\n",
            "Iteration: 125, loss: 1238448.750000\n",
            "Iteration: 150, loss: 845326.125000\n",
            "Iteration: 175, loss: 649624.750000\n",
            "Iteration: 200, loss: 543536.562500\n",
            "Iteration: 225, loss: 479831.281250\n",
            "Iteration: 250, loss: 436915.812500\n",
            "Iteration: 275, loss: 407236.937500\n",
            "Iteration: 300, loss: 386128.343750\n",
            "Iteration: 325, loss: 369616.437500\n",
            "Iteration: 350, loss: 355638.812500\n",
            "Iteration: 375, loss: 345045.750000\n",
            "Iteration: 400, loss: 336038.125000\n",
            "Iteration: 425, loss: 328294.687500\n",
            "Iteration: 450, loss: 321790.593750\n",
            "Iteration: 475, loss: 316287.875000\n",
            "Iteration: 500, loss: 311486.406250\n",
            "Iteration: 525, loss: 307076.000000\n",
            "Iteration: 550, loss: 303335.562500\n",
            "Iteration: 575, loss: 299913.468750\n",
            "Iteration: 600, loss: 296897.875000\n",
            "Iteration: 625, loss: 294280.968750\n",
            "Iteration: 650, loss: 291952.093750\n",
            "Iteration: 675, loss: 289784.281250\n",
            "Iteration: 700, loss: 287800.093750\n",
            "Iteration: 725, loss: 285896.843750\n",
            "Iteration: 750, loss: 284254.000000\n",
            "Iteration: 775, loss: 282609.218750\n",
            "Iteration: 800, loss: 281039.125000\n",
            "Iteration: 825, loss: 279658.218750\n",
            "Iteration: 850, loss: 278339.781250\n",
            "Iteration: 875, loss: 277147.156250\n",
            "Iteration: 900, loss: 276067.656250\n",
            "Iteration: 925, loss: 275026.281250\n",
            "Iteration: 950, loss: 274056.718750\n",
            "Iteration: 975, loss: 273137.437500\n",
            "Iteration: 1000, loss: 272298.218750\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"content\", 1000, 25, output_dir+'content_max_1000/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 10131554.000000\n",
            "Iteration: 50, loss: 2678002.000000\n",
            "Iteration: 75, loss: 1500881.250000\n",
            "Iteration: 100, loss: 1013247.250000\n",
            "Iteration: 125, loss: 788849.062500\n",
            "Iteration: 150, loss: 671130.562500\n",
            "Iteration: 175, loss: 592678.750000\n",
            "Iteration: 200, loss: 534708.062500\n",
            "Iteration: 225, loss: 496823.531250\n",
            "Iteration: 250, loss: 466063.781250\n",
            "Iteration: 275, loss: 441006.468750\n",
            "Iteration: 300, loss: 421002.250000\n",
            "Iteration: 325, loss: 404888.625000\n",
            "Iteration: 350, loss: 389762.406250\n",
            "Iteration: 375, loss: 377068.968750\n",
            "Iteration: 400, loss: 366042.875000\n",
            "Iteration: 425, loss: 355803.593750\n",
            "Iteration: 450, loss: 346746.312500\n",
            "Iteration: 475, loss: 338776.156250\n",
            "Iteration: 500, loss: 331278.718750\n",
            "Iteration: 525, loss: 324448.312500\n",
            "Iteration: 550, loss: 318383.343750\n",
            "Iteration: 575, loss: 313026.812500\n",
            "Iteration: 600, loss: 308078.906250\n",
            "Iteration: 625, loss: 303305.812500\n",
            "Iteration: 650, loss: 298956.187500\n",
            "Iteration: 675, loss: 294919.312500\n",
            "Iteration: 700, loss: 291288.656250\n",
            "Iteration: 725, loss: 287801.781250\n",
            "Iteration: 750, loss: 284880.406250\n",
            "Iteration: 775, loss: 281951.187500\n",
            "Iteration: 800, loss: 279258.281250\n",
            "Iteration: 825, loss: 276623.687500\n",
            "Iteration: 850, loss: 274400.500000\n",
            "Iteration: 875, loss: 272252.781250\n",
            "Iteration: 900, loss: 270202.281250\n",
            "Iteration: 925, loss: 268264.187500\n",
            "Iteration: 950, loss: 266615.875000\n",
            "Iteration: 975, loss: 265003.656250\n",
            "Iteration: 1000, loss: 263416.093750\n",
            "Iteration: 25, loss: 8404383.000000\n",
            "Iteration: 50, loss: 2458538.250000\n",
            "Iteration: 75, loss: 1367448.875000\n",
            "Iteration: 100, loss: 963865.125000\n",
            "Iteration: 125, loss: 764617.750000\n",
            "Iteration: 150, loss: 623183.062500\n",
            "Iteration: 175, loss: 523242.562500\n",
            "Iteration: 200, loss: 449984.375000\n",
            "Iteration: 225, loss: 393437.156250\n",
            "Iteration: 250, loss: 350071.937500\n",
            "Iteration: 275, loss: 317336.250000\n",
            "Iteration: 300, loss: 292317.968750\n",
            "Iteration: 325, loss: 273418.875000\n",
            "Iteration: 350, loss: 259071.312500\n",
            "Iteration: 375, loss: 247439.515625\n",
            "Iteration: 400, loss: 237203.406250\n",
            "Iteration: 425, loss: 228697.312500\n",
            "Iteration: 450, loss: 221659.546875\n",
            "Iteration: 475, loss: 215422.375000\n",
            "Iteration: 500, loss: 209891.015625\n",
            "Iteration: 525, loss: 205047.046875\n",
            "Iteration: 550, loss: 200202.250000\n",
            "Iteration: 575, loss: 195812.125000\n",
            "Iteration: 600, loss: 192032.703125\n",
            "Iteration: 625, loss: 188514.234375\n",
            "Iteration: 650, loss: 185264.937500\n",
            "Iteration: 675, loss: 182268.187500\n",
            "Iteration: 700, loss: 179396.828125\n",
            "Iteration: 725, loss: 176745.734375\n",
            "Iteration: 750, loss: 174491.312500\n",
            "Iteration: 775, loss: 172359.671875\n",
            "Iteration: 800, loss: 170342.062500\n",
            "Iteration: 825, loss: 168462.921875\n",
            "Iteration: 850, loss: 166763.406250\n",
            "Iteration: 875, loss: 165192.500000\n",
            "Iteration: 900, loss: 163700.640625\n",
            "Iteration: 925, loss: 162239.687500\n",
            "Iteration: 950, loss: 160761.578125\n",
            "Iteration: 975, loss: 159426.281250\n",
            "Iteration: 1000, loss: 158112.718750\n",
            "Iteration: 25, loss: 190319760.000000\n",
            "Iteration: 50, loss: 27894412.000000\n",
            "Iteration: 75, loss: 12006726.000000\n",
            "Iteration: 100, loss: 7495846.000000\n",
            "Iteration: 125, loss: 5128777.000000\n",
            "Iteration: 150, loss: 3934704.750000\n",
            "Iteration: 175, loss: 3230711.500000\n",
            "Iteration: 200, loss: 2772374.000000\n",
            "Iteration: 225, loss: 2412157.500000\n",
            "Iteration: 250, loss: 2154458.000000\n",
            "Iteration: 275, loss: 1933669.500000\n",
            "Iteration: 300, loss: 1764026.625000\n",
            "Iteration: 325, loss: 1626514.625000\n",
            "Iteration: 350, loss: 1510516.875000\n",
            "Iteration: 375, loss: 1412702.500000\n",
            "Iteration: 400, loss: 1330469.250000\n",
            "Iteration: 425, loss: 1258915.625000\n",
            "Iteration: 450, loss: 1195478.875000\n",
            "Iteration: 475, loss: 1144315.750000\n",
            "Iteration: 500, loss: 1097199.250000\n",
            "Iteration: 525, loss: 1056148.125000\n",
            "Iteration: 550, loss: 1020171.750000\n",
            "Iteration: 575, loss: 990583.125000\n",
            "Iteration: 600, loss: 962671.187500\n",
            "Iteration: 625, loss: 938231.750000\n",
            "Iteration: 650, loss: 916192.125000\n",
            "Iteration: 675, loss: 897902.062500\n",
            "Iteration: 700, loss: 879691.500000\n",
            "Iteration: 725, loss: 864347.500000\n",
            "Iteration: 750, loss: 850318.062500\n",
            "Iteration: 775, loss: 837299.562500\n",
            "Iteration: 800, loss: 825409.875000\n",
            "Iteration: 825, loss: 814283.875000\n",
            "Iteration: 850, loss: 804592.125000\n",
            "Iteration: 875, loss: 795366.437500\n",
            "Iteration: 900, loss: 786758.125000\n",
            "Iteration: 925, loss: 778483.125000\n",
            "Iteration: 950, loss: 771316.625000\n",
            "Iteration: 975, loss: 764174.062500\n",
            "Iteration: 1000, loss: 757578.250000\n",
            "Iteration: 25, loss: 54302744.000000\n",
            "Iteration: 50, loss: 11725392.000000\n",
            "Iteration: 75, loss: 6691784.000000\n",
            "Iteration: 100, loss: 4685108.500000\n",
            "Iteration: 125, loss: 3692552.250000\n",
            "Iteration: 150, loss: 3055911.000000\n",
            "Iteration: 175, loss: 2608078.000000\n",
            "Iteration: 200, loss: 2242547.750000\n",
            "Iteration: 225, loss: 1957135.875000\n",
            "Iteration: 250, loss: 1722749.750000\n",
            "Iteration: 275, loss: 1514893.500000\n",
            "Iteration: 300, loss: 1331956.750000\n",
            "Iteration: 325, loss: 1186888.750000\n",
            "Iteration: 350, loss: 1070430.750000\n",
            "Iteration: 375, loss: 972126.375000\n",
            "Iteration: 400, loss: 895483.687500\n",
            "Iteration: 425, loss: 831460.375000\n",
            "Iteration: 450, loss: 779803.500000\n",
            "Iteration: 475, loss: 736389.125000\n",
            "Iteration: 500, loss: 701214.125000\n",
            "Iteration: 525, loss: 670886.437500\n",
            "Iteration: 550, loss: 643364.812500\n",
            "Iteration: 575, loss: 619107.812500\n",
            "Iteration: 600, loss: 598305.312500\n",
            "Iteration: 625, loss: 579660.625000\n",
            "Iteration: 650, loss: 563449.562500\n",
            "Iteration: 675, loss: 548540.312500\n",
            "Iteration: 700, loss: 534994.500000\n",
            "Iteration: 725, loss: 522678.375000\n",
            "Iteration: 750, loss: 511305.468750\n",
            "Iteration: 775, loss: 501294.687500\n",
            "Iteration: 800, loss: 491986.687500\n",
            "Iteration: 825, loss: 483215.781250\n",
            "Iteration: 850, loss: 474925.312500\n",
            "Iteration: 875, loss: 467437.500000\n",
            "Iteration: 900, loss: 460908.937500\n",
            "Iteration: 925, loss: 454838.375000\n",
            "Iteration: 950, loss: 449032.125000\n",
            "Iteration: 975, loss: 443535.281250\n",
            "Iteration: 1000, loss: 438326.312500\n",
            "Iteration: 25, loss: 56301936.000000\n",
            "Iteration: 50, loss: 9541596.000000\n",
            "Iteration: 75, loss: 4904023.500000\n",
            "Iteration: 100, loss: 3244916.500000\n",
            "Iteration: 125, loss: 2458369.000000\n",
            "Iteration: 150, loss: 1994420.500000\n",
            "Iteration: 175, loss: 1692030.250000\n",
            "Iteration: 200, loss: 1475325.500000\n",
            "Iteration: 225, loss: 1308770.625000\n",
            "Iteration: 250, loss: 1180052.250000\n",
            "Iteration: 275, loss: 1084502.500000\n",
            "Iteration: 300, loss: 1000805.375000\n",
            "Iteration: 325, loss: 936914.125000\n",
            "Iteration: 350, loss: 882619.250000\n",
            "Iteration: 375, loss: 839940.875000\n",
            "Iteration: 400, loss: 800596.250000\n",
            "Iteration: 425, loss: 767817.875000\n",
            "Iteration: 450, loss: 737579.375000\n",
            "Iteration: 475, loss: 712339.562500\n",
            "Iteration: 500, loss: 689538.187500\n",
            "Iteration: 525, loss: 667964.125000\n",
            "Iteration: 550, loss: 649437.500000\n",
            "Iteration: 575, loss: 633175.562500\n",
            "Iteration: 600, loss: 618988.625000\n",
            "Iteration: 625, loss: 606230.937500\n",
            "Iteration: 650, loss: 594814.125000\n",
            "Iteration: 675, loss: 584285.625000\n",
            "Iteration: 700, loss: 575036.812500\n",
            "Iteration: 725, loss: 566249.375000\n",
            "Iteration: 750, loss: 558331.375000\n",
            "Iteration: 775, loss: 551261.750000\n",
            "Iteration: 800, loss: 544287.500000\n",
            "Iteration: 825, loss: 538151.375000\n",
            "Iteration: 850, loss: 532404.937500\n",
            "Iteration: 875, loss: 526924.312500\n",
            "Iteration: 900, loss: 521653.187500\n",
            "Iteration: 925, loss: 517145.093750\n",
            "Iteration: 950, loss: 512602.625000\n",
            "Iteration: 975, loss: 508461.687500\n",
            "Iteration: 1000, loss: 504428.125000\n",
            "Iteration: 25, loss: 24121140.000000\n",
            "Iteration: 50, loss: 2866885.500000\n",
            "Iteration: 75, loss: 1528942.000000\n",
            "Iteration: 100, loss: 1054274.000000\n",
            "Iteration: 125, loss: 817081.687500\n",
            "Iteration: 150, loss: 687286.187500\n",
            "Iteration: 175, loss: 600916.125000\n",
            "Iteration: 200, loss: 531341.437500\n",
            "Iteration: 225, loss: 478598.093750\n",
            "Iteration: 250, loss: 440045.625000\n",
            "Iteration: 275, loss: 410560.375000\n",
            "Iteration: 300, loss: 388296.812500\n",
            "Iteration: 325, loss: 371944.125000\n",
            "Iteration: 350, loss: 359634.687500\n",
            "Iteration: 375, loss: 349088.031250\n",
            "Iteration: 400, loss: 340526.625000\n",
            "Iteration: 425, loss: 333466.125000\n",
            "Iteration: 450, loss: 327415.281250\n",
            "Iteration: 475, loss: 322156.937500\n",
            "Iteration: 500, loss: 317408.687500\n",
            "Iteration: 525, loss: 313360.812500\n",
            "Iteration: 550, loss: 309856.656250\n",
            "Iteration: 575, loss: 306648.843750\n",
            "Iteration: 600, loss: 303725.875000\n",
            "Iteration: 625, loss: 300974.125000\n",
            "Iteration: 650, loss: 298498.312500\n",
            "Iteration: 675, loss: 296269.312500\n",
            "Iteration: 700, loss: 294159.000000\n",
            "Iteration: 725, loss: 292183.187500\n",
            "Iteration: 750, loss: 290468.062500\n",
            "Iteration: 775, loss: 288836.093750\n",
            "Iteration: 800, loss: 287278.000000\n",
            "Iteration: 825, loss: 285860.937500\n",
            "Iteration: 850, loss: 284505.687500\n",
            "Iteration: 875, loss: 283200.687500\n",
            "Iteration: 900, loss: 281971.031250\n",
            "Iteration: 925, loss: 280861.781250\n",
            "Iteration: 950, loss: 279810.375000\n",
            "Iteration: 975, loss: 278725.875000\n",
            "Iteration: 1000, loss: 277761.687500\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"random\", 1000, 25, output_dir+'random_max_1000/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 701564.500000\n",
            "Iteration: 50, loss: 471712.250000\n",
            "Iteration: 75, loss: 410368.593750\n",
            "Iteration: 100, loss: 379672.937500\n",
            "Iteration: 125, loss: 358543.343750\n",
            "Iteration: 150, loss: 343154.625000\n",
            "Iteration: 175, loss: 330984.125000\n",
            "Iteration: 200, loss: 321053.343750\n",
            "Iteration: 225, loss: 313224.625000\n",
            "Iteration: 250, loss: 306429.187500\n",
            "Iteration: 275, loss: 300547.156250\n",
            "Iteration: 300, loss: 295761.937500\n",
            "Iteration: 325, loss: 291526.812500\n",
            "Iteration: 350, loss: 287549.531250\n",
            "Iteration: 375, loss: 284056.468750\n",
            "Iteration: 400, loss: 280987.656250\n",
            "Iteration: 425, loss: 278144.093750\n",
            "Iteration: 450, loss: 275485.500000\n",
            "Iteration: 475, loss: 273030.375000\n",
            "Iteration: 500, loss: 270956.687500\n",
            "Iteration: 525, loss: 268882.531250\n",
            "Iteration: 550, loss: 266967.281250\n",
            "Iteration: 575, loss: 265237.937500\n",
            "Iteration: 600, loss: 263637.562500\n",
            "Iteration: 625, loss: 262103.656250\n",
            "Iteration: 650, loss: 260630.218750\n",
            "Iteration: 675, loss: 259298.109375\n",
            "Iteration: 700, loss: 258011.031250\n",
            "Iteration: 725, loss: 256946.828125\n",
            "Iteration: 750, loss: 255830.734375\n",
            "Iteration: 775, loss: 254771.953125\n",
            "Iteration: 800, loss: 253779.375000\n",
            "Iteration: 825, loss: 252878.187500\n",
            "Iteration: 850, loss: 251989.203125\n",
            "Iteration: 875, loss: 251168.687500\n",
            "Iteration: 900, loss: 250370.000000\n",
            "Iteration: 925, loss: 249639.203125\n",
            "Iteration: 950, loss: 248913.531250\n",
            "Iteration: 975, loss: 248266.281250\n",
            "Iteration: 1000, loss: 247625.437500\n",
            "Iteration: 25, loss: 505196.906250\n",
            "Iteration: 50, loss: 371015.812500\n",
            "Iteration: 75, loss: 321531.406250\n",
            "Iteration: 100, loss: 292988.625000\n",
            "Iteration: 125, loss: 272836.312500\n",
            "Iteration: 150, loss: 258237.593750\n",
            "Iteration: 175, loss: 246839.015625\n",
            "Iteration: 200, loss: 237587.156250\n",
            "Iteration: 225, loss: 229978.781250\n",
            "Iteration: 250, loss: 223515.875000\n",
            "Iteration: 275, loss: 217812.687500\n",
            "Iteration: 300, loss: 212718.937500\n",
            "Iteration: 325, loss: 208105.937500\n",
            "Iteration: 350, loss: 203929.843750\n",
            "Iteration: 375, loss: 200104.859375\n",
            "Iteration: 400, loss: 196635.375000\n",
            "Iteration: 425, loss: 193412.234375\n",
            "Iteration: 450, loss: 190335.390625\n",
            "Iteration: 475, loss: 187268.421875\n",
            "Iteration: 500, loss: 184514.125000\n",
            "Iteration: 525, loss: 181808.843750\n",
            "Iteration: 550, loss: 179475.875000\n",
            "Iteration: 575, loss: 177367.140625\n",
            "Iteration: 600, loss: 175315.578125\n",
            "Iteration: 625, loss: 173549.703125\n",
            "Iteration: 650, loss: 171817.156250\n",
            "Iteration: 675, loss: 170187.562500\n",
            "Iteration: 700, loss: 168634.500000\n",
            "Iteration: 725, loss: 167089.953125\n",
            "Iteration: 750, loss: 165747.640625\n",
            "Iteration: 775, loss: 164415.687500\n",
            "Iteration: 800, loss: 163188.109375\n",
            "Iteration: 825, loss: 162039.937500\n",
            "Iteration: 850, loss: 160867.500000\n",
            "Iteration: 875, loss: 159834.906250\n",
            "Iteration: 900, loss: 158798.437500\n",
            "Iteration: 925, loss: 157804.109375\n",
            "Iteration: 950, loss: 156895.093750\n",
            "Iteration: 975, loss: 156040.406250\n",
            "Iteration: 1000, loss: 155180.968750\n",
            "Iteration: 25, loss: 2559878.000000\n",
            "Iteration: 50, loss: 1336633.250000\n",
            "Iteration: 75, loss: 1076849.000000\n",
            "Iteration: 100, loss: 961366.125000\n",
            "Iteration: 125, loss: 898175.312500\n",
            "Iteration: 150, loss: 857190.000000\n",
            "Iteration: 175, loss: 827466.187500\n",
            "Iteration: 200, loss: 804422.375000\n",
            "Iteration: 225, loss: 785626.562500\n",
            "Iteration: 250, loss: 770172.250000\n",
            "Iteration: 275, loss: 756206.187500\n",
            "Iteration: 300, loss: 745003.437500\n",
            "Iteration: 325, loss: 734830.750000\n",
            "Iteration: 350, loss: 725877.500000\n",
            "Iteration: 375, loss: 718017.250000\n",
            "Iteration: 400, loss: 710832.062500\n",
            "Iteration: 425, loss: 704674.187500\n",
            "Iteration: 450, loss: 698460.062500\n",
            "Iteration: 475, loss: 693070.250000\n",
            "Iteration: 500, loss: 688158.437500\n",
            "Iteration: 525, loss: 683441.875000\n",
            "Iteration: 550, loss: 679008.750000\n",
            "Iteration: 575, loss: 675004.375000\n",
            "Iteration: 600, loss: 671239.562500\n",
            "Iteration: 625, loss: 667886.625000\n",
            "Iteration: 650, loss: 664708.812500\n",
            "Iteration: 675, loss: 661790.000000\n",
            "Iteration: 700, loss: 658831.062500\n",
            "Iteration: 725, loss: 656022.812500\n",
            "Iteration: 750, loss: 653364.500000\n",
            "Iteration: 775, loss: 650864.812500\n",
            "Iteration: 800, loss: 648373.187500\n",
            "Iteration: 825, loss: 646225.375000\n",
            "Iteration: 850, loss: 644056.937500\n",
            "Iteration: 875, loss: 641844.437500\n",
            "Iteration: 900, loss: 639865.000000\n",
            "Iteration: 925, loss: 637920.125000\n",
            "Iteration: 950, loss: 636077.875000\n",
            "Iteration: 975, loss: 634347.875000\n",
            "Iteration: 1000, loss: 632557.375000\n",
            "Iteration: 25, loss: 2138940.750000\n",
            "Iteration: 50, loss: 958131.437500\n",
            "Iteration: 75, loss: 711930.312500\n",
            "Iteration: 100, loss: 609734.562500\n",
            "Iteration: 125, loss: 552015.500000\n",
            "Iteration: 150, loss: 514879.187500\n",
            "Iteration: 175, loss: 486957.625000\n",
            "Iteration: 200, loss: 466345.031250\n",
            "Iteration: 225, loss: 449422.437500\n",
            "Iteration: 250, loss: 436339.218750\n",
            "Iteration: 275, loss: 425031.031250\n",
            "Iteration: 300, loss: 415050.031250\n",
            "Iteration: 325, loss: 405951.656250\n",
            "Iteration: 350, loss: 398476.812500\n",
            "Iteration: 375, loss: 391712.406250\n",
            "Iteration: 400, loss: 385725.437500\n",
            "Iteration: 425, loss: 380122.875000\n",
            "Iteration: 450, loss: 374942.406250\n",
            "Iteration: 475, loss: 370312.656250\n",
            "Iteration: 500, loss: 365991.750000\n",
            "Iteration: 525, loss: 362355.468750\n",
            "Iteration: 550, loss: 358565.093750\n",
            "Iteration: 575, loss: 355189.656250\n",
            "Iteration: 600, loss: 352028.312500\n",
            "Iteration: 625, loss: 348955.156250\n",
            "Iteration: 650, loss: 346130.031250\n",
            "Iteration: 675, loss: 343404.781250\n",
            "Iteration: 700, loss: 340871.750000\n",
            "Iteration: 725, loss: 338500.375000\n",
            "Iteration: 750, loss: 336224.062500\n",
            "Iteration: 775, loss: 334025.625000\n",
            "Iteration: 800, loss: 331940.125000\n",
            "Iteration: 825, loss: 329981.125000\n",
            "Iteration: 850, loss: 328198.562500\n",
            "Iteration: 875, loss: 326352.531250\n",
            "Iteration: 900, loss: 324622.906250\n",
            "Iteration: 925, loss: 322894.625000\n",
            "Iteration: 950, loss: 321315.031250\n",
            "Iteration: 975, loss: 319833.968750\n",
            "Iteration: 1000, loss: 318386.906250\n",
            "Iteration: 25, loss: 1207929.125000\n",
            "Iteration: 50, loss: 733005.562500\n",
            "Iteration: 75, loss: 647399.062500\n",
            "Iteration: 100, loss: 603883.875000\n",
            "Iteration: 125, loss: 577754.625000\n",
            "Iteration: 150, loss: 558683.437500\n",
            "Iteration: 175, loss: 544854.625000\n",
            "Iteration: 200, loss: 532917.812500\n",
            "Iteration: 225, loss: 523043.437500\n",
            "Iteration: 250, loss: 514445.187500\n",
            "Iteration: 275, loss: 507009.406250\n",
            "Iteration: 300, loss: 500421.500000\n",
            "Iteration: 325, loss: 494483.687500\n",
            "Iteration: 350, loss: 489098.500000\n",
            "Iteration: 375, loss: 484329.468750\n",
            "Iteration: 400, loss: 479956.375000\n",
            "Iteration: 425, loss: 475800.500000\n",
            "Iteration: 450, loss: 471955.937500\n",
            "Iteration: 475, loss: 468410.593750\n",
            "Iteration: 500, loss: 465067.312500\n",
            "Iteration: 525, loss: 462169.375000\n",
            "Iteration: 550, loss: 459294.843750\n",
            "Iteration: 575, loss: 456559.375000\n",
            "Iteration: 600, loss: 454060.968750\n",
            "Iteration: 625, loss: 451737.812500\n",
            "Iteration: 650, loss: 449390.468750\n",
            "Iteration: 675, loss: 447114.687500\n",
            "Iteration: 700, loss: 445009.093750\n",
            "Iteration: 725, loss: 443080.281250\n",
            "Iteration: 750, loss: 441106.500000\n",
            "Iteration: 775, loss: 439300.812500\n",
            "Iteration: 800, loss: 437593.375000\n",
            "Iteration: 825, loss: 435953.375000\n",
            "Iteration: 850, loss: 434279.187500\n",
            "Iteration: 875, loss: 432741.718750\n",
            "Iteration: 900, loss: 431210.125000\n",
            "Iteration: 925, loss: 429773.406250\n",
            "Iteration: 950, loss: 428313.250000\n",
            "Iteration: 975, loss: 427048.250000\n",
            "Iteration: 1000, loss: 425698.875000\n",
            "Iteration: 25, loss: 636884.000000\n",
            "Iteration: 50, loss: 467383.250000\n",
            "Iteration: 75, loss: 418317.406250\n",
            "Iteration: 100, loss: 389169.125000\n",
            "Iteration: 125, loss: 369305.281250\n",
            "Iteration: 150, loss: 354483.625000\n",
            "Iteration: 175, loss: 344099.031250\n",
            "Iteration: 200, loss: 335023.531250\n",
            "Iteration: 225, loss: 327875.718750\n",
            "Iteration: 250, loss: 321639.906250\n",
            "Iteration: 275, loss: 316495.343750\n",
            "Iteration: 300, loss: 311899.375000\n",
            "Iteration: 325, loss: 308338.062500\n",
            "Iteration: 350, loss: 304791.218750\n",
            "Iteration: 375, loss: 301779.687500\n",
            "Iteration: 400, loss: 298974.656250\n",
            "Iteration: 425, loss: 296495.437500\n",
            "Iteration: 450, loss: 294284.468750\n",
            "Iteration: 475, loss: 292188.093750\n",
            "Iteration: 500, loss: 290296.750000\n",
            "Iteration: 525, loss: 288491.125000\n",
            "Iteration: 550, loss: 286837.250000\n",
            "Iteration: 575, loss: 285292.718750\n",
            "Iteration: 600, loss: 283854.187500\n",
            "Iteration: 625, loss: 282470.312500\n",
            "Iteration: 650, loss: 281189.062500\n",
            "Iteration: 675, loss: 280012.218750\n",
            "Iteration: 700, loss: 278853.312500\n",
            "Iteration: 725, loss: 277901.437500\n",
            "Iteration: 750, loss: 276995.937500\n",
            "Iteration: 775, loss: 276140.531250\n",
            "Iteration: 800, loss: 275298.562500\n",
            "Iteration: 825, loss: 274447.125000\n",
            "Iteration: 850, loss: 273645.718750\n",
            "Iteration: 875, loss: 272920.281250\n",
            "Iteration: 900, loss: 272228.000000\n",
            "Iteration: 925, loss: 271580.375000\n",
            "Iteration: 950, loss: 270923.625000\n",
            "Iteration: 975, loss: 270291.468750\n",
            "Iteration: 1000, loss: 269681.937500\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"style\", 1000, 25, output_dir+'style_max_1000/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 5091098.500000\n",
            "Iteration: 50, loss: 2153164.750000\n",
            "Iteration: 75, loss: 1155976.500000\n",
            "Iteration: 100, loss: 811592.500000\n",
            "Iteration: 125, loss: 635150.750000\n",
            "Iteration: 150, loss: 532106.000000\n",
            "Iteration: 175, loss: 459781.187500\n",
            "Iteration: 200, loss: 410490.312500\n",
            "Iteration: 225, loss: 376840.562500\n",
            "Iteration: 250, loss: 351696.250000\n",
            "Iteration: 275, loss: 331125.093750\n",
            "Iteration: 300, loss: 314608.750000\n",
            "Iteration: 325, loss: 302379.375000\n",
            "Iteration: 350, loss: 292460.250000\n",
            "Iteration: 375, loss: 284660.062500\n",
            "Iteration: 400, loss: 277998.687500\n",
            "Iteration: 425, loss: 272761.250000\n",
            "Iteration: 450, loss: 268501.937500\n",
            "Iteration: 475, loss: 264718.187500\n",
            "Iteration: 500, loss: 261393.390625\n",
            "Iteration: 25, loss: 5120862.500000\n",
            "Iteration: 50, loss: 2641978.000000\n",
            "Iteration: 75, loss: 1738827.125000\n",
            "Iteration: 100, loss: 1170056.375000\n",
            "Iteration: 125, loss: 831802.500000\n",
            "Iteration: 150, loss: 615108.750000\n",
            "Iteration: 175, loss: 473728.812500\n",
            "Iteration: 200, loss: 377879.656250\n",
            "Iteration: 225, loss: 316216.562500\n",
            "Iteration: 250, loss: 275280.843750\n",
            "Iteration: 275, loss: 245078.578125\n",
            "Iteration: 300, loss: 223839.406250\n",
            "Iteration: 325, loss: 208257.546875\n",
            "Iteration: 350, loss: 196423.218750\n",
            "Iteration: 375, loss: 187556.953125\n",
            "Iteration: 400, loss: 180695.656250\n",
            "Iteration: 425, loss: 174985.093750\n",
            "Iteration: 450, loss: 170368.234375\n",
            "Iteration: 475, loss: 166470.593750\n",
            "Iteration: 500, loss: 163183.140625\n",
            "Iteration: 25, loss: 17730892.000000\n",
            "Iteration: 50, loss: 7064060.000000\n",
            "Iteration: 75, loss: 4401409.000000\n",
            "Iteration: 100, loss: 3123628.750000\n",
            "Iteration: 125, loss: 2409851.750000\n",
            "Iteration: 150, loss: 1962607.250000\n",
            "Iteration: 175, loss: 1658909.500000\n",
            "Iteration: 200, loss: 1432794.625000\n",
            "Iteration: 225, loss: 1261864.000000\n",
            "Iteration: 250, loss: 1136308.500000\n",
            "Iteration: 275, loss: 1040357.750000\n",
            "Iteration: 300, loss: 963928.375000\n",
            "Iteration: 325, loss: 906168.500000\n",
            "Iteration: 350, loss: 856345.937500\n",
            "Iteration: 375, loss: 813333.125000\n",
            "Iteration: 400, loss: 778291.500000\n",
            "Iteration: 425, loss: 749325.125000\n",
            "Iteration: 450, loss: 725167.562500\n",
            "Iteration: 475, loss: 704049.562500\n",
            "Iteration: 500, loss: 685267.937500\n",
            "Iteration: 25, loss: 9868115.000000\n",
            "Iteration: 50, loss: 3975642.250000\n",
            "Iteration: 75, loss: 2446812.500000\n",
            "Iteration: 100, loss: 1736090.000000\n",
            "Iteration: 125, loss: 1313001.375000\n",
            "Iteration: 150, loss: 1041261.875000\n",
            "Iteration: 175, loss: 850434.750000\n",
            "Iteration: 200, loss: 721341.812500\n",
            "Iteration: 225, loss: 634435.250000\n",
            "Iteration: 250, loss: 571579.000000\n",
            "Iteration: 275, loss: 522572.968750\n",
            "Iteration: 300, loss: 485362.187500\n",
            "Iteration: 325, loss: 455126.625000\n",
            "Iteration: 350, loss: 432258.250000\n",
            "Iteration: 375, loss: 413215.062500\n",
            "Iteration: 400, loss: 398971.812500\n",
            "Iteration: 425, loss: 387870.500000\n",
            "Iteration: 450, loss: 377276.437500\n",
            "Iteration: 475, loss: 367650.687500\n",
            "Iteration: 500, loss: 359585.281250\n",
            "Iteration: 25, loss: 3759422.000000\n",
            "Iteration: 50, loss: 1717104.250000\n",
            "Iteration: 75, loss: 1183071.000000\n",
            "Iteration: 100, loss: 938422.937500\n",
            "Iteration: 125, loss: 798615.500000\n",
            "Iteration: 150, loss: 707138.125000\n",
            "Iteration: 175, loss: 641417.937500\n",
            "Iteration: 200, loss: 593684.687500\n",
            "Iteration: 225, loss: 556884.250000\n",
            "Iteration: 250, loss: 528916.687500\n",
            "Iteration: 275, loss: 506946.937500\n",
            "Iteration: 300, loss: 489418.187500\n",
            "Iteration: 325, loss: 474369.500000\n",
            "Iteration: 350, loss: 461356.937500\n",
            "Iteration: 375, loss: 450987.812500\n",
            "Iteration: 400, loss: 441746.062500\n",
            "Iteration: 425, loss: 433713.000000\n",
            "Iteration: 450, loss: 426999.906250\n",
            "Iteration: 475, loss: 420972.687500\n",
            "Iteration: 500, loss: 415591.437500\n",
            "Iteration: 25, loss: 20573818.000000\n",
            "Iteration: 50, loss: 7088743.000000\n",
            "Iteration: 75, loss: 4011475.500000\n",
            "Iteration: 100, loss: 2253189.750000\n",
            "Iteration: 125, loss: 1279907.000000\n",
            "Iteration: 150, loss: 868637.500000\n",
            "Iteration: 175, loss: 667773.437500\n",
            "Iteration: 200, loss: 561673.625000\n",
            "Iteration: 225, loss: 486281.281250\n",
            "Iteration: 250, loss: 442923.687500\n",
            "Iteration: 275, loss: 411625.437500\n",
            "Iteration: 300, loss: 389055.687500\n",
            "Iteration: 325, loss: 371289.875000\n",
            "Iteration: 350, loss: 357916.750000\n",
            "Iteration: 375, loss: 346725.500000\n",
            "Iteration: 400, loss: 337591.218750\n",
            "Iteration: 425, loss: 329809.000000\n",
            "Iteration: 450, loss: 323526.781250\n",
            "Iteration: 475, loss: 317521.906250\n",
            "Iteration: 500, loss: 312595.062500\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"content\", 500, 25, output_dir+'content_max_500/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 10536864.000000\n",
            "Iteration: 50, loss: 2887640.000000\n",
            "Iteration: 75, loss: 1561258.750000\n",
            "Iteration: 100, loss: 1038391.375000\n",
            "Iteration: 125, loss: 803683.625000\n",
            "Iteration: 150, loss: 670243.375000\n",
            "Iteration: 175, loss: 589323.125000\n",
            "Iteration: 200, loss: 533084.312500\n",
            "Iteration: 225, loss: 492078.000000\n",
            "Iteration: 250, loss: 462309.687500\n",
            "Iteration: 275, loss: 436911.312500\n",
            "Iteration: 300, loss: 418018.750000\n",
            "Iteration: 325, loss: 401803.375000\n",
            "Iteration: 350, loss: 387497.218750\n",
            "Iteration: 375, loss: 374886.156250\n",
            "Iteration: 400, loss: 364519.375000\n",
            "Iteration: 425, loss: 354666.531250\n",
            "Iteration: 450, loss: 345647.437500\n",
            "Iteration: 475, loss: 338247.812500\n",
            "Iteration: 500, loss: 331622.812500\n",
            "Iteration: 25, loss: 7394907.500000\n",
            "Iteration: 50, loss: 2303478.250000\n",
            "Iteration: 75, loss: 1341082.250000\n",
            "Iteration: 100, loss: 937297.750000\n",
            "Iteration: 125, loss: 727957.875000\n",
            "Iteration: 150, loss: 600754.375000\n",
            "Iteration: 175, loss: 503188.562500\n",
            "Iteration: 200, loss: 434982.093750\n",
            "Iteration: 225, loss: 383794.031250\n",
            "Iteration: 250, loss: 343327.187500\n",
            "Iteration: 275, loss: 312841.250000\n",
            "Iteration: 300, loss: 291309.593750\n",
            "Iteration: 325, loss: 273232.406250\n",
            "Iteration: 350, loss: 258627.218750\n",
            "Iteration: 375, loss: 247758.406250\n",
            "Iteration: 400, loss: 237901.000000\n",
            "Iteration: 425, loss: 229366.562500\n",
            "Iteration: 450, loss: 222331.609375\n",
            "Iteration: 475, loss: 216594.453125\n",
            "Iteration: 500, loss: 211337.234375\n",
            "Iteration: 25, loss: 179360384.000000\n",
            "Iteration: 50, loss: 27826912.000000\n",
            "Iteration: 75, loss: 11983890.000000\n",
            "Iteration: 100, loss: 7144180.000000\n",
            "Iteration: 125, loss: 5043205.500000\n",
            "Iteration: 150, loss: 3979336.500000\n",
            "Iteration: 175, loss: 3259653.750000\n",
            "Iteration: 200, loss: 2781625.250000\n",
            "Iteration: 225, loss: 2455146.500000\n",
            "Iteration: 250, loss: 2173344.500000\n",
            "Iteration: 275, loss: 1958852.500000\n",
            "Iteration: 300, loss: 1775732.750000\n",
            "Iteration: 325, loss: 1630032.750000\n",
            "Iteration: 350, loss: 1515251.250000\n",
            "Iteration: 375, loss: 1413498.750000\n",
            "Iteration: 400, loss: 1330214.750000\n",
            "Iteration: 425, loss: 1258791.000000\n",
            "Iteration: 450, loss: 1195851.000000\n",
            "Iteration: 475, loss: 1144166.250000\n",
            "Iteration: 500, loss: 1097323.250000\n",
            "Iteration: 25, loss: 62042776.000000\n",
            "Iteration: 50, loss: 12852936.000000\n",
            "Iteration: 75, loss: 6975608.000000\n",
            "Iteration: 100, loss: 4865927.500000\n",
            "Iteration: 125, loss: 3791840.500000\n",
            "Iteration: 150, loss: 3111268.750000\n",
            "Iteration: 175, loss: 2606951.000000\n",
            "Iteration: 200, loss: 2255637.000000\n",
            "Iteration: 225, loss: 1966878.000000\n",
            "Iteration: 250, loss: 1709315.250000\n",
            "Iteration: 275, loss: 1508550.500000\n",
            "Iteration: 300, loss: 1354790.875000\n",
            "Iteration: 325, loss: 1223829.000000\n",
            "Iteration: 350, loss: 1115200.500000\n",
            "Iteration: 375, loss: 1026002.875000\n",
            "Iteration: 400, loss: 956678.000000\n",
            "Iteration: 425, loss: 893810.125000\n",
            "Iteration: 450, loss: 841317.437500\n",
            "Iteration: 475, loss: 798056.437500\n",
            "Iteration: 500, loss: 761230.812500\n",
            "Iteration: 25, loss: 56234892.000000\n",
            "Iteration: 50, loss: 9626478.000000\n",
            "Iteration: 75, loss: 4840910.500000\n",
            "Iteration: 100, loss: 3312530.500000\n",
            "Iteration: 125, loss: 2506794.000000\n",
            "Iteration: 150, loss: 2035393.000000\n",
            "Iteration: 175, loss: 1714223.250000\n",
            "Iteration: 200, loss: 1476523.250000\n",
            "Iteration: 225, loss: 1299917.000000\n",
            "Iteration: 250, loss: 1166036.375000\n",
            "Iteration: 275, loss: 1063916.625000\n",
            "Iteration: 300, loss: 978709.875000\n",
            "Iteration: 325, loss: 911210.750000\n",
            "Iteration: 350, loss: 855877.937500\n",
            "Iteration: 375, loss: 812186.562500\n",
            "Iteration: 400, loss: 776563.375000\n",
            "Iteration: 425, loss: 746556.500000\n",
            "Iteration: 450, loss: 721118.625000\n",
            "Iteration: 475, loss: 699510.000000\n",
            "Iteration: 500, loss: 680258.750000\n",
            "Iteration: 25, loss: 19600726.000000\n",
            "Iteration: 50, loss: 3070328.000000\n",
            "Iteration: 75, loss: 1517965.000000\n",
            "Iteration: 100, loss: 1061567.250000\n",
            "Iteration: 125, loss: 827126.000000\n",
            "Iteration: 150, loss: 695120.875000\n",
            "Iteration: 175, loss: 603994.187500\n",
            "Iteration: 200, loss: 535932.687500\n",
            "Iteration: 225, loss: 485354.125000\n",
            "Iteration: 250, loss: 444847.343750\n",
            "Iteration: 275, loss: 415826.187500\n",
            "Iteration: 300, loss: 392542.187500\n",
            "Iteration: 325, loss: 375225.468750\n",
            "Iteration: 350, loss: 362214.781250\n",
            "Iteration: 375, loss: 351926.000000\n",
            "Iteration: 400, loss: 342965.218750\n",
            "Iteration: 425, loss: 335510.593750\n",
            "Iteration: 450, loss: 328993.843750\n",
            "Iteration: 475, loss: 323606.312500\n",
            "Iteration: 500, loss: 318848.125000\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"random\", 500, 25, output_dir+'random_max_500/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 702499.687500\n",
            "Iteration: 50, loss: 473849.281250\n",
            "Iteration: 75, loss: 409961.593750\n",
            "Iteration: 100, loss: 377760.062500\n",
            "Iteration: 125, loss: 357124.125000\n",
            "Iteration: 150, loss: 342206.343750\n",
            "Iteration: 175, loss: 330645.406250\n",
            "Iteration: 200, loss: 321063.687500\n",
            "Iteration: 225, loss: 312703.625000\n",
            "Iteration: 250, loss: 306059.687500\n",
            "Iteration: 275, loss: 300106.093750\n",
            "Iteration: 300, loss: 295100.562500\n",
            "Iteration: 325, loss: 290944.781250\n",
            "Iteration: 350, loss: 287171.937500\n",
            "Iteration: 375, loss: 283679.875000\n",
            "Iteration: 400, loss: 280536.500000\n",
            "Iteration: 425, loss: 277709.062500\n",
            "Iteration: 450, loss: 275221.312500\n",
            "Iteration: 475, loss: 272899.218750\n",
            "Iteration: 500, loss: 270664.187500\n",
            "Iteration: 25, loss: 504315.875000\n",
            "Iteration: 50, loss: 373784.812500\n",
            "Iteration: 75, loss: 323607.437500\n",
            "Iteration: 100, loss: 294990.125000\n",
            "Iteration: 125, loss: 275122.562500\n",
            "Iteration: 150, loss: 260057.015625\n",
            "Iteration: 175, loss: 248023.421875\n",
            "Iteration: 200, loss: 238850.656250\n",
            "Iteration: 225, loss: 231196.203125\n",
            "Iteration: 250, loss: 224481.796875\n",
            "Iteration: 275, loss: 218556.781250\n",
            "Iteration: 300, loss: 213301.015625\n",
            "Iteration: 325, loss: 208939.875000\n",
            "Iteration: 350, loss: 204765.390625\n",
            "Iteration: 375, loss: 201054.281250\n",
            "Iteration: 400, loss: 197785.765625\n",
            "Iteration: 425, loss: 194534.546875\n",
            "Iteration: 450, loss: 191512.500000\n",
            "Iteration: 475, loss: 188790.515625\n",
            "Iteration: 500, loss: 186146.390625\n",
            "Iteration: 25, loss: 2552913.250000\n",
            "Iteration: 50, loss: 1326698.500000\n",
            "Iteration: 75, loss: 1077890.875000\n",
            "Iteration: 100, loss: 967452.312500\n",
            "Iteration: 125, loss: 902353.812500\n",
            "Iteration: 150, loss: 861226.312500\n",
            "Iteration: 175, loss: 832693.250000\n",
            "Iteration: 200, loss: 808507.562500\n",
            "Iteration: 225, loss: 789175.687500\n",
            "Iteration: 250, loss: 772977.500000\n",
            "Iteration: 275, loss: 760064.250000\n",
            "Iteration: 300, loss: 748463.062500\n",
            "Iteration: 325, loss: 738292.187500\n",
            "Iteration: 350, loss: 728923.687500\n",
            "Iteration: 375, loss: 720843.312500\n",
            "Iteration: 400, loss: 713465.437500\n",
            "Iteration: 425, loss: 706913.062500\n",
            "Iteration: 450, loss: 700885.000000\n",
            "Iteration: 475, loss: 695441.250000\n",
            "Iteration: 500, loss: 690488.312500\n",
            "Iteration: 25, loss: 2123555.000000\n",
            "Iteration: 50, loss: 966763.000000\n",
            "Iteration: 75, loss: 699667.125000\n",
            "Iteration: 100, loss: 598600.375000\n",
            "Iteration: 125, loss: 545560.625000\n",
            "Iteration: 150, loss: 509886.031250\n",
            "Iteration: 175, loss: 483772.750000\n",
            "Iteration: 200, loss: 463024.218750\n",
            "Iteration: 225, loss: 447301.468750\n",
            "Iteration: 250, loss: 434080.281250\n",
            "Iteration: 275, loss: 423007.750000\n",
            "Iteration: 300, loss: 413552.031250\n",
            "Iteration: 325, loss: 404996.312500\n",
            "Iteration: 350, loss: 397598.281250\n",
            "Iteration: 375, loss: 391131.531250\n",
            "Iteration: 400, loss: 385139.562500\n",
            "Iteration: 425, loss: 379857.375000\n",
            "Iteration: 450, loss: 374739.312500\n",
            "Iteration: 475, loss: 370162.750000\n",
            "Iteration: 500, loss: 365928.093750\n",
            "Iteration: 25, loss: 1207696.750000\n",
            "Iteration: 50, loss: 724631.562500\n",
            "Iteration: 75, loss: 639983.125000\n",
            "Iteration: 100, loss: 601801.500000\n",
            "Iteration: 125, loss: 576636.312500\n",
            "Iteration: 150, loss: 558657.187500\n",
            "Iteration: 175, loss: 544282.250000\n",
            "Iteration: 200, loss: 532749.375000\n",
            "Iteration: 225, loss: 522945.625000\n",
            "Iteration: 250, loss: 514151.687500\n",
            "Iteration: 275, loss: 506495.468750\n",
            "Iteration: 300, loss: 500102.093750\n",
            "Iteration: 325, loss: 494019.000000\n",
            "Iteration: 350, loss: 488955.593750\n",
            "Iteration: 375, loss: 484150.437500\n",
            "Iteration: 400, loss: 479847.437500\n",
            "Iteration: 425, loss: 475946.343750\n",
            "Iteration: 450, loss: 472191.062500\n",
            "Iteration: 475, loss: 468671.125000\n",
            "Iteration: 500, loss: 465291.156250\n",
            "Iteration: 25, loss: 631936.937500\n",
            "Iteration: 50, loss: 462444.687500\n",
            "Iteration: 75, loss: 415929.343750\n",
            "Iteration: 100, loss: 387705.781250\n",
            "Iteration: 125, loss: 367943.718750\n",
            "Iteration: 150, loss: 354168.593750\n",
            "Iteration: 175, loss: 342948.593750\n",
            "Iteration: 200, loss: 334377.843750\n",
            "Iteration: 225, loss: 326904.937500\n",
            "Iteration: 250, loss: 320804.593750\n",
            "Iteration: 275, loss: 315672.437500\n",
            "Iteration: 300, loss: 311060.593750\n",
            "Iteration: 325, loss: 307197.187500\n",
            "Iteration: 350, loss: 303824.343750\n",
            "Iteration: 375, loss: 300745.937500\n",
            "Iteration: 400, loss: 298086.375000\n",
            "Iteration: 425, loss: 295692.250000\n",
            "Iteration: 450, loss: 293462.062500\n",
            "Iteration: 475, loss: 291347.968750\n",
            "Iteration: 500, loss: 289491.906250\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"style\", 500, 25, output_dir+'style_max_500/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 5143563.000000\n",
            "Iteration: 50, loss: 2198793.250000\n",
            "Iteration: 75, loss: 1182373.000000\n",
            "Iteration: 100, loss: 809456.125000\n",
            "Iteration: 125, loss: 641733.312500\n",
            "Iteration: 150, loss: 532434.000000\n",
            "Iteration: 175, loss: 463777.125000\n",
            "Iteration: 200, loss: 415517.000000\n",
            "Iteration: 25, loss: 5121996.000000\n",
            "Iteration: 50, loss: 2619085.500000\n",
            "Iteration: 75, loss: 1743929.125000\n",
            "Iteration: 100, loss: 1185993.375000\n",
            "Iteration: 125, loss: 830016.687500\n",
            "Iteration: 150, loss: 613204.500000\n",
            "Iteration: 175, loss: 470243.031250\n",
            "Iteration: 200, loss: 379376.031250\n",
            "Iteration: 25, loss: 17658918.000000\n",
            "Iteration: 50, loss: 7105019.000000\n",
            "Iteration: 75, loss: 4434058.000000\n",
            "Iteration: 100, loss: 3162647.500000\n",
            "Iteration: 125, loss: 2482081.000000\n",
            "Iteration: 150, loss: 2000787.000000\n",
            "Iteration: 175, loss: 1688461.750000\n",
            "Iteration: 200, loss: 1449708.875000\n",
            "Iteration: 25, loss: 10034986.000000\n",
            "Iteration: 50, loss: 3918653.000000\n",
            "Iteration: 75, loss: 2387052.750000\n",
            "Iteration: 100, loss: 1679854.500000\n",
            "Iteration: 125, loss: 1268545.250000\n",
            "Iteration: 150, loss: 1011366.000000\n",
            "Iteration: 175, loss: 828121.937500\n",
            "Iteration: 200, loss: 716118.875000\n",
            "Iteration: 25, loss: 3740113.500000\n",
            "Iteration: 50, loss: 1712299.750000\n",
            "Iteration: 75, loss: 1185238.750000\n",
            "Iteration: 100, loss: 939789.250000\n",
            "Iteration: 125, loss: 802849.250000\n",
            "Iteration: 150, loss: 708659.500000\n",
            "Iteration: 175, loss: 645653.937500\n",
            "Iteration: 200, loss: 596415.062500\n",
            "Iteration: 25, loss: 20750030.000000\n",
            "Iteration: 50, loss: 7024976.500000\n",
            "Iteration: 75, loss: 3858987.000000\n",
            "Iteration: 100, loss: 2201490.500000\n",
            "Iteration: 125, loss: 1242953.875000\n",
            "Iteration: 150, loss: 830072.375000\n",
            "Iteration: 175, loss: 644719.125000\n",
            "Iteration: 200, loss: 537256.375000\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"content\", 200, 25, output_dir+'content_max_200/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 10212059.000000\n",
            "Iteration: 50, loss: 2893102.750000\n",
            "Iteration: 75, loss: 1557538.250000\n",
            "Iteration: 100, loss: 1041842.375000\n",
            "Iteration: 125, loss: 807530.125000\n",
            "Iteration: 150, loss: 674186.875000\n",
            "Iteration: 175, loss: 592682.625000\n",
            "Iteration: 200, loss: 538276.375000\n",
            "Iteration: 25, loss: 16956642.000000\n",
            "Iteration: 50, loss: 2925112.750000\n",
            "Iteration: 75, loss: 1518258.250000\n",
            "Iteration: 100, loss: 1053215.625000\n",
            "Iteration: 125, loss: 806758.062500\n",
            "Iteration: 150, loss: 661936.062500\n",
            "Iteration: 175, loss: 562541.375000\n",
            "Iteration: 200, loss: 476111.468750\n",
            "Iteration: 25, loss: 277711936.000000\n",
            "Iteration: 50, loss: 31838964.000000\n",
            "Iteration: 75, loss: 12741678.000000\n",
            "Iteration: 100, loss: 7503704.000000\n",
            "Iteration: 125, loss: 5170290.000000\n",
            "Iteration: 150, loss: 4001757.000000\n",
            "Iteration: 175, loss: 3240161.000000\n",
            "Iteration: 200, loss: 2781249.000000\n",
            "Iteration: 25, loss: 52515300.000000\n",
            "Iteration: 50, loss: 11394668.000000\n",
            "Iteration: 75, loss: 6583137.000000\n",
            "Iteration: 100, loss: 4757225.500000\n",
            "Iteration: 125, loss: 3765124.000000\n",
            "Iteration: 150, loss: 3092861.000000\n",
            "Iteration: 175, loss: 2629268.750000\n",
            "Iteration: 200, loss: 2250590.750000\n",
            "Iteration: 25, loss: 44450204.000000\n",
            "Iteration: 50, loss: 9288275.000000\n",
            "Iteration: 75, loss: 4911187.500000\n",
            "Iteration: 100, loss: 3257677.750000\n",
            "Iteration: 125, loss: 2477471.000000\n",
            "Iteration: 150, loss: 2047810.500000\n",
            "Iteration: 175, loss: 1723561.875000\n",
            "Iteration: 200, loss: 1489537.750000\n",
            "Iteration: 25, loss: 25011854.000000\n",
            "Iteration: 50, loss: 3017030.000000\n",
            "Iteration: 75, loss: 1601407.750000\n",
            "Iteration: 100, loss: 1089344.125000\n",
            "Iteration: 125, loss: 846124.500000\n",
            "Iteration: 150, loss: 705800.750000\n",
            "Iteration: 175, loss: 608531.312500\n",
            "Iteration: 200, loss: 538024.625000\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"random\", 200, 25, output_dir+'random_max_200/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 25, loss: 701721.687500\n",
            "Iteration: 50, loss: 472717.125000\n",
            "Iteration: 75, loss: 409268.781250\n",
            "Iteration: 100, loss: 378440.812500\n",
            "Iteration: 125, loss: 358258.875000\n",
            "Iteration: 150, loss: 343154.656250\n",
            "Iteration: 175, loss: 331153.750000\n",
            "Iteration: 200, loss: 321549.500000\n",
            "Iteration: 25, loss: 506126.218750\n",
            "Iteration: 50, loss: 370783.437500\n",
            "Iteration: 75, loss: 321644.906250\n",
            "Iteration: 100, loss: 291961.406250\n",
            "Iteration: 125, loss: 272869.312500\n",
            "Iteration: 150, loss: 258553.828125\n",
            "Iteration: 175, loss: 247383.671875\n",
            "Iteration: 200, loss: 237961.812500\n",
            "Iteration: 25, loss: 2458601.500000\n",
            "Iteration: 50, loss: 1368556.750000\n",
            "Iteration: 75, loss: 1092145.125000\n",
            "Iteration: 100, loss: 971419.500000\n",
            "Iteration: 125, loss: 903417.625000\n",
            "Iteration: 150, loss: 859793.000000\n",
            "Iteration: 175, loss: 830845.625000\n",
            "Iteration: 200, loss: 808404.875000\n",
            "Iteration: 25, loss: 2123459.750000\n",
            "Iteration: 50, loss: 976211.562500\n",
            "Iteration: 75, loss: 702705.125000\n",
            "Iteration: 100, loss: 611995.062500\n",
            "Iteration: 125, loss: 548691.937500\n",
            "Iteration: 150, loss: 510477.375000\n",
            "Iteration: 175, loss: 483971.781250\n",
            "Iteration: 200, loss: 462848.937500\n",
            "Iteration: 25, loss: 1199512.625000\n",
            "Iteration: 50, loss: 731466.875000\n",
            "Iteration: 75, loss: 645280.750000\n",
            "Iteration: 100, loss: 604680.312500\n",
            "Iteration: 125, loss: 579111.125000\n",
            "Iteration: 150, loss: 559867.625000\n",
            "Iteration: 175, loss: 546100.000000\n",
            "Iteration: 200, loss: 533788.187500\n",
            "Iteration: 25, loss: 632297.625000\n",
            "Iteration: 50, loss: 461274.218750\n",
            "Iteration: 75, loss: 414992.562500\n",
            "Iteration: 100, loss: 386705.875000\n",
            "Iteration: 125, loss: 367575.281250\n",
            "Iteration: 150, loss: 353802.968750\n",
            "Iteration: 175, loss: 342861.468750\n",
            "Iteration: 200, loss: 334088.281250\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(style_images)):\n",
        "    run_transfer(style_images[i], content_images[i], \"style\", 200, 25, output_dir+'style_max_200/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test block, will eventually remove it\n",
        "#temp1 = Image.open(image_dir+style_name)\n",
        "#img_resize = transforms.Resize((temp.height, temp.width))\n",
        "#temp_resized = img_resize(temp1)\n",
        "#plt.imshow(temp_resized)\n",
        "#temp_resized.save(output_dir + \"c\" + content_name[8:10] + \"_s\" + style_name[6:8] + \".png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NeuralStyleTransfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
